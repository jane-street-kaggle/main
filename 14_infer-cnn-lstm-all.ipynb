{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-01-12T10:29:31.550401Z","iopub.status.busy":"2025-01-12T10:29:31.550072Z","iopub.status.idle":"2025-01-12T10:29:38.292694Z","shell.execute_reply":"2025-01-12T10:29:38.291754Z","shell.execute_reply.started":"2025-01-12T10:29:31.550371Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import polars as pl\n","import time\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import torch"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","import statistics as stat\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import roc_auc_score\n","import copy\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","import torch.optim as optim\n","import copy\n","import polars as pl"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-01-12T10:30:06.177297Z","iopub.status.busy":"2025-01-12T10:30:06.176665Z","iopub.status.idle":"2025-01-12T10:30:06.187613Z","shell.execute_reply":"2025-01-12T10:30:06.186792Z","shell.execute_reply.started":"2025-01-12T10:30:06.177255Z"},"trusted":true},"outputs":[],"source":["class LSTM(nn.Module):\n","    def __init__(self,\n","                 num_features: int,\n","                 hidden_size: int = 128,\n","                 num_layers: int = 1,\n","                 output_size: int = 1,\n","                 dropout_rate: float = 0.5):\n","        super(LSTM, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.expand = nn.Sequential(\n","            nn.LayerNorm(num_features),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(num_features, hidden_size),\n","            nn.ReLU()\n","        )\n","\n","        # Convolutional layers with corrected in_channels\n","        self.conv1 = nn.Sequential(\n","            nn.Conv1d(in_channels=self.hidden_size // 16, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool1d(kernel_size=2)\n","        )\n","        \n","        self.conv2 = nn.Sequential(\n","            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool1d(kernel_size=2)\n","        )\n","\n","        # LSTM layer\n","        self.lstm = nn.LSTM(\n","            input_size=128,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            dropout=dropout_rate if num_layers > 1 else 0\n","        )\n","\n","        # Fully connected layer\n","        self.fc = nn.Sequential(\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(hidden_size, output_size),\n","            nn.Tanh()\n","        )\n","    \n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        for name, param in self.lstm.named_parameters():\n","            if 'weight_ih' in name:\n","                nn.init.xavier_uniform_(param.data)\n","            elif 'weight_hh' in name:\n","                nn.init.orthogonal_(param.data)\n","            elif 'bias' in name:\n","                param.data.fill_(0)\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_features)\n","        x = self.expand(x)\n","        batch_size = x.size(0)\n","        seq_length = x.size(1) // (self.hidden_size // 16)\n","        x = x.view(batch_size, self.hidden_size // 16, seq_length)\n","\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        \n","        # Prepare for LSTM\n","        x = x.permute(0, 2, 1)  # (batch_size, seq_length, features)\n","        \n","        # Initialize hidden and cell states\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","\n","        self.lstm.flatten_parameters()\n","\n","        # LSTM layer\n","        out, _ = self.lstm(x, (h0, c0))\n","\n","        # Output layer\n","        out = self.fc(out[:, -1, :])\n","        return out.squeeze()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class LSTM_RES(nn.Module):\n","    def __init__(self,\n","                 num_features: int,\n","                 hidden_size: int = 128,\n","                 num_layers: int = 1,\n","                 output_size: int = 1,\n","                 dropout_rate: float = 0.5):\n","        super(LSTM_RES, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.expand = nn.Sequential(\n","            nn.LayerNorm(num_features),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(num_features, hidden_size),\n","            nn.ReLU()\n","        )\n","\n","        # Convolutional layers\n","        self.conv1 = nn.Sequential(\n","            nn.Conv1d(in_channels=self.hidden_size // 16, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool1d(kernel_size=2)\n","        )\n","        \n","        self.conv2 = nn.Sequential(\n","            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool1d(kernel_size=2)\n","        )\n","\n","        # Residual connection for convolutional layers\n","        self.residual_conv = nn.Sequential(\n","            nn.Conv1d(in_channels=self.hidden_size // 16, out_channels=128, kernel_size=1),\n","            nn.MaxPool1d(kernel_size=4)\n","        )\n","\n","        # LSTM layer\n","        self.lstm = nn.LSTM(\n","            input_size=128,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            dropout=dropout_rate if num_layers > 1 else 0\n","        )\n","\n","        # Fully connected layer\n","        self.fc = nn.Sequential(\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(hidden_size, output_size),\n","            nn.Tanh()\n","        )\n","    \n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        for name, param in self.lstm.named_parameters():\n","            if 'weight_ih' in name:\n","                nn.init.xavier_uniform_(param.data)\n","            elif 'weight_hh' in name:\n","                nn.init.orthogonal_(param.data)\n","            elif 'bias' in name:\n","                param.data.fill_(0)\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, num_features)\n","        x = self.expand(x)\n","        batch_size = x.size(0)\n","        seq_length = x.size(1) // (self.hidden_size // 16)\n","        x = x.view(batch_size, self.hidden_size // 16, seq_length)\n","\n","        # Save input for residual connection\n","        residual = x.clone()\n","\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        \n","        # Apply residual connection\n","        residual = self.residual_conv(residual)\n","        x += residual\n","\n","        # Prepare for LSTM\n","        x = x.permute(0, 2, 1)  # (batch_size, seq_length, features)\n","\n","        # Initialize hidden and cell states\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","\n","        self.lstm.flatten_parameters()\n","\n","        # LSTM layer\n","        out, _ = self.lstm(x, (h0, c0))\n","\n","        # Output layer\n","        out = self.fc(out[:, -1, :])\n","        return out.squeeze()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2025-01-12T10:33:33.172287Z","iopub.status.busy":"2025-01-12T10:33:33.171508Z","iopub.status.idle":"2025-01-12T10:33:33.200772Z","shell.execute_reply":"2025-01-12T10:33:33.199913Z","shell.execute_reply.started":"2025-01-12T10:33:33.172250Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_original = LSTM(num_features=79, hidden_size=512, output_size = 1, num_layers = 1).to(device)\n","model_res = LSTM_RES(num_features=79, hidden_size=512, output_size = 1, num_layers = 1).to(device)\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2025-01-12T10:33:34.343930Z","iopub.status.busy":"2025-01-12T10:33:34.343603Z","iopub.status.idle":"2025-01-12T10:33:34.364079Z","shell.execute_reply":"2025-01-12T10:33:34.363178Z","shell.execute_reply.started":"2025-01-12T10:33:34.343900Z"},"trusted":true},"outputs":[],"source":["means = {'feature_00': 0.640198826789856, 'feature_01': 0.03755598142743111, 'feature_02': 0.6368075609207153, 'feature_03': 0.6365063786506653, 'feature_04': 0.013741530478000641, 'feature_05': -0.02173694409430027, 'feature_06': -0.006415014620870352, 'feature_07': -0.010971736162900925, 'feature_08': -0.04653771221637726, 'feature_09': 32.596106194690265, 'feature_10': 4.95929203539823, 'feature_11': 167.6541592920354, 'feature_12': -0.13415881991386414, 'feature_13': -0.07573335617780685, 'feature_14': -0.12015637010335922, 'feature_15': -0.7470195889472961, 'feature_16': -0.6257441639900208, 'feature_17': -0.7294047474861145, 'feature_18': -0.042215555906295776, 'feature_19': -0.08798160403966904, 'feature_20': -0.15741558372974396, 'feature_21': 0.10528526455163956, 'feature_22': 0.018054703250527382, 'feature_23': 0.03165541961789131, 'feature_24': 2.733017921447754, 'feature_25': 0.39958420395851135, 'feature_26': -0.11045943945646286, 'feature_27': -0.5332594513893127, 'feature_28': -0.4522790312767029, 'feature_29': -0.5739678144454956, 'feature_30': -0.7905704975128174, 'feature_31': 0.10600688308477402, 'feature_32': 0.40044134855270386, 'feature_33': -0.021725023165345192, 'feature_34': 0.4226262867450714, 'feature_35': 0.42143046855926514, 'feature_36': -0.00023802756913937628, 'feature_37': 0.027961043640971184, 'feature_38': 0.010258913040161133, 'feature_39': 0.005768273025751114, 'feature_40': 0.017485467717051506, 'feature_41': 0.038347117602825165, 'feature_42': -0.06123563274741173, 'feature_43': -0.11644423753023148, 'feature_44': -0.12342483550310135, 'feature_45': -0.028769943863153458, 'feature_46': -0.015200662426650524, 'feature_47': 0.015717582777142525, 'feature_48': -0.0033910537604242563, 'feature_49': -0.0052393232472240925, 'feature_50': -0.2285808026790619, 'feature_51': -0.3548349440097809, 'feature_52': -0.358092725276947, 'feature_53': 0.2607136368751526, 'feature_54': 0.18796788156032562, 'feature_55': 0.3154229521751404, 'feature_56': -0.1471923440694809, 'feature_57': 0.15730056166648865, 'feature_58': -0.021774644032120705, 'feature_59': -0.0037768862675875425, 'feature_60': -0.010220836848020554, 'feature_61': -0.03178725391626358, 'feature_62': -0.3769100308418274, 'feature_63': -0.3229374587535858, 'feature_64': -0.3718394339084625, 'feature_65': -0.10233989357948303, 'feature_66': -0.13688170909881592, 'feature_67': -0.14402112364768982, 'feature_68': -0.06875362992286682, 'feature_69': -0.11862917989492416, 'feature_70': -0.11789549142122269, 'feature_71': -0.06013699993491173, 'feature_72': -0.10766122490167618, 'feature_73': -0.09921672940254211, 'feature_74': -0.10233042389154434, 'feature_75': -0.05991339311003685, 'feature_76': -0.06349952518939972, 'feature_77': -0.07424316555261612, 'feature_78': -0.07759837061166763}\n","stds = {'feature_00': 1.027751088142395, 'feature_01': 1.0967519283294678, 'feature_02': 1.0156300067901611, 'feature_03': 1.0170334577560425, 'feature_04': 1.0726385116577148, 'feature_05': 0.9639211297035217, 'feature_06': 1.0963259935379028, 'feature_07': 1.0789952278137207, 'feature_08': 0.7962697148323059, 'feature_09': 23.72976726545254, 'feature_10': 3.1867162933797224, 'feature_11': 163.44513161352285, 'feature_12': 0.6700984835624695, 'feature_13': 0.5805172920227051, 'feature_14': 0.664044201374054, 'feature_15': 0.37517768144607544, 'feature_16': 0.3393096327781677, 'feature_17': 0.3603287935256958, 'feature_18': 0.9911752939224243, 'feature_19': 1.0550744533538818, 'feature_20': 0.6643751263618469, 'feature_21': 0.38239365816116333, 'feature_22': 0.950261116027832, 'feature_23': 0.8119344711303711, 'feature_24': 1.4362775087356567, 'feature_25': 1.0947270393371582, 'feature_26': 1.077124834060669, 'feature_27': 1.0645726919174194, 'feature_28': 1.0676648616790771, 'feature_29': 0.2640742361545563, 'feature_30': 0.19689509272575378, 'feature_31': 0.3815343976020813, 'feature_32': 1.2996565103530884, 'feature_33': 0.9989405870437622, 'feature_34': 1.3409572839736938, 'feature_35': 1.3365675210952759, 'feature_36': 0.8695492148399353, 'feature_37': 0.7334080934524536, 'feature_38': 0.698810338973999, 'feature_39': 0.7965824604034424, 'feature_40': 0.518515944480896, 'feature_41': 0.6384949088096619, 'feature_42': 0.8168442249298096, 'feature_43': 0.5228385925292969, 'feature_44': 0.6521403193473816, 'feature_45': 0.8666537404060364, 'feature_46': 0.9039222002029419, 'feature_47': 3.2711963653564453, 'feature_48': 0.6570901274681091, 'feature_49': 0.7083076238632202, 'feature_50': 1.0132617950439453, 'feature_51': 0.6081287860870361, 'feature_52': 0.9250587224960327, 'feature_53': 1.0421689748764038, 'feature_54': 0.5859629511833191, 'feature_55': 0.9191848039627075, 'feature_56': 0.9549097418785095, 'feature_57': 1.0204777717590332, 'feature_58': 0.8327276110649109, 'feature_59': 0.8309783339500427, 'feature_60': 0.8389413356781006, 'feature_61': 1.192766547203064, 'feature_62': 1.388945460319519, 'feature_63': 0.09957146644592285, 'feature_64': 0.3396177291870117, 'feature_65': 1.01683509349823, 'feature_66': 1.0824761390686035, 'feature_67': 0.642227828502655, 'feature_68': 0.5312599539756775, 'feature_69': 0.6208390593528748, 'feature_70': 0.6724499464035034, 'feature_71': 0.5356909036636353, 'feature_72': 0.6534596681594849, 'feature_73': 1.0855497121810913, 'feature_74': 1.0880277156829834, 'feature_75': 1.2321789264678955, 'feature_76': 1.2345560789108276, 'feature_77': 1.0921478271484375, 'feature_78': 1.0924347639083862}\n","def normalize_dataframe(df: pl.DataFrame, means: dict, stds: dict) -> pl.DataFrame:\n","    \"\"\"\n","    Normalize a Polars DataFrame using the provided means and standard deviations.\n","\n","    Args:\n","    df (pl.DataFrame): The input DataFrame to normalize\n","    means (dict): A dictionary of column means\n","    stds (dict): A dictionary of column standard deviations\n","\n","    Returns:\n","    pl.DataFrame: The normalized DataFrame\n","    \"\"\"\n","\n","    # Create a list to store our normalization expressions\n","    normalize_exprs = []\n","\n","    for col in df.columns:\n","        if col in means and col in stds:\n","            # Ensure we don't divide by zero\n","            if stds[col] != 0:\n","                normalize_exprs.append(\n","                    ((pl.col(col) - means[col]) / stds[col]).alias(col)\n","                )\n","            else:\n","                # If std is 0, just subtract the mean\n","                normalize_exprs.append(\n","                    (pl.col(col) - means[col]).alias(col)\n","                )\n","        else:\n","            # If we don't have mean/std for this column, leave it as is\n","            normalize_exprs.append(pl.col(col))\n","\n","    # Apply the normalization to the dataframe\n","    normalized_df = df.select(normalize_exprs)\n","\n","    return normalized_df\n","    \n","def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n","    \"\"\"Make a prediction.\"\"\"\n","    global model_original\n","    global model_res\n","    global device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    model_original.load_state_dict(\n","        torch.load(\n","            '/kaggle/input/js-cnn-lstm/cnn-lstm-adamw.pth',\n","            map_location=device,\n","            weights_only=True\n","        )\n","    )\n","    model_res.load_state_dict(\n","        torch.load(\n","            \"/kaggle/input/js-cnn-lstm-res/cnn-lstm-adamw-res.pth\", \n","            map_location=device,\n","            weights_only=True\n","        )\n","    )\n","    model_original.eval()  # Set the model to evaluation mode\n","    sel_cols  = [f\"feature_{i:02d}\" for i in range(79)]\n","    missing_cols = set(sel_cols) - set(test.columns)\n","    if missing_cols:\n","        raise ValueError(f\"Missing columns in test data: {missing_cols}\")\n","    test_features = test.select(sel_cols)\n","    test_features = test_features.fill_null(strategy='forward').fill_null(0)\n","    test_features = normalize_dataframe(test_features,means,stds)\n","    X_test = test_features.to_numpy()\n","    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n","    with torch.no_grad():\n","        outputs_original    = model_original(X_test_tensor)\n","        outputs_main        = model_res(X_test_tensor)\n","        predictions_original= outputs_original.squeeze().cpu().numpy() * 0.4\n","        predictions_main    = outputs_main.squeeze().cpu().numpy() * 0.6\n","    predictions_df = pl.DataFrame({\n","        'row_id': test['row_id'],\n","        'responder_6': predictions_original + predictions_main\n","    })\n","    assert isinstance(predictions_df, (pl.DataFrame, pd.DataFrame))\n","    assert predictions_df.columns == ['row_id', 'responder_6']\n","    assert len(predictions_df) == len(test)\n","    return predictions_df"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2025-01-12T10:33:35.547046Z","iopub.status.busy":"2025-01-12T10:33:35.546226Z","iopub.status.idle":"2025-01-12T10:33:35.550621Z","shell.execute_reply":"2025-01-12T10:33:35.549754Z","shell.execute_reply.started":"2025-01-12T10:33:35.547012Z"},"trusted":true},"outputs":[],"source":["import kaggle_evaluation.jane_street_inference_server"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2025-01-12T10:33:37.395257Z","iopub.status.busy":"2025-01-12T10:33:37.394906Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'kaggle_evaluation' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m<timed exec>:1\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'kaggle_evaluation' is not defined"]}],"source":["%%time\n","\n","inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n","test_dir = '/kaggle/input/jane-street-realtime-marketdata-forecasting/test.parquet'\n","lags_dir = '/kaggle/input/jane-street-realtime-marketdata-forecasting/lags.parquet'\n","\n","\n","if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n","    inference_server.serve()\n","else:\n","    inference_server.run_local_gateway(\n","        (\n","            test_dir,\n","            lags_dir,\n","        )\n","    )"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9871156,"sourceId":84493,"sourceType":"competition"},{"datasetId":5912994,"sourceId":9675091,"sourceType":"datasetVersion"},{"datasetId":6468327,"sourceId":10449773,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":4}
