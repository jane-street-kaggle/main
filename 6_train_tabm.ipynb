{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TabNet-Training: Attentive Interpretable Tabular Learning\n",
    "https://www.kaggle.com/code/i2nfinit3y/jane-street-tabm-ft-transformer-training/notebook\n",
    "\n",
    "# TabNet-Inference\n",
    "https://www.kaggle.com/code/i2nfinit3y/jane-street-tabm-ft-transformer-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import rtdl_num_embeddings\n",
    "from rtdl_num_embeddings import compute_bins\n",
    "import rtdl_revisiting_models\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, ConcatDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import delu\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple\n",
    "\n",
    "import joblib\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "feature_train_list = [f\"feature_{idx:02d}\" for idx in range(79)] \n",
    "target_col = \"responder_6\"\n",
    "feature_train = feature_train_list \\\n",
    "                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "\n",
    "start_dt = 110\n",
    "end_dt = 1577\n",
    "\n",
    "feature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\n",
    "feature_cont = [item for item in feature_train if item not in feature_cat]\n",
    "std_feature = [i for i in feature_train_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "batch_size = 8192\n",
    "num_epochs = 100\n",
    "\n",
    "data_stats = joblib.load(\"/kaggle/input/jane-street-data-preprocessing/data_stats.pkl\")\n",
    "means = data_stats['mean']\n",
    "stds = data_stats['std']\n",
    "\n",
    "def standardize(df, feature_cols, means, stds):\n",
    "    return df.with_columns([\n",
    "        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch found in feature_09:\n",
      "category_mappings[feature_09]: {12: 0, 9: 1, 15: 2, 30: 3, 42: 4, 57: 5, 81: 6, 4: 7, 25: 8, 34: 9, 46: 10, 49: 11, 64: 12, 70: 13, 82: 14, 2: 15, 11: 16, 14: 17, 26: 18, 44: 19, 50: 20, 68: 21}\n",
      "_category_mappings[feature_09]: {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21}\n",
      "Mismatch found in feature_10:\n",
      "category_mappings[feature_10]: {6: 0, 3: 1, 12: 2, 4: 3, 1: 4, 10: 5, 7: 6, 2: 7, 5: 8}\n",
      "_category_mappings[feature_10]: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8}\n",
      "Mismatch found in feature_11:\n",
      "category_mappings[feature_11]: {9: 0, 539: 1, 24: 2, 158: 3, 48: 4, 63: 5, 66: 6, 230: 7, 376: 8, 388: 9, 522: 10, 534: 11, 16: 12, 13: 13, 150: 14, 159: 15, 25: 16, 34: 17, 40: 18, 171: 19, 195: 20, 76: 21, 261: 22, 11: 23, 410: 24, 297: 25, 50: 26, 59: 27, 62: 28, 336: 29, 214: 30}\n",
      "_category_mappings[feature_11]: {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13, 76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30}\n",
      "Mismatch found in symbol_id:\n",
      "category_mappings[symbol_id]: {6: 0, 0: 1, 3: 2, 9: 3, 12: 4, 18: 5, 15: 6, 21: 7, 24: 8, 27: 9, 30: 10, 33: 11, 36: 12, 4: 13, 1: 14, 7: 15, 10: 16, 16: 17, 13: 18, 22: 19, 19: 20, 28: 21, 25: 22, 31: 23, 34: 24, 37: 25, 2: 26, 8: 27, 5: 28, 11: 29, 14: 30, 17: 31, 20: 32, 26: 33, 23: 34, 32: 35, 29: 36, 38: 37, 35: 38}\n",
      "_category_mappings[symbol_id]: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38}\n",
      "Mismatch found in time_id:\n",
      "category_mappings[time_id]: {658: 0, 268: 1, 265: 2, 0: 3, 137: 4, 527: 5, 6: 6, 3: 7, 399: 8, 792: 9, 923: 10, 396: 11, 789: 12, 920: 13, 661: 14, 134: 15, 530: 16, 664: 17, 9: 18, 143: 19, 12: 20, 274: 21, 533: 22, 929: 23, 140: 24, 795: 25, 926: 26, 271: 27, 667: 28, 405: 29, 402: 30, 536: 31, 798: 32, 804: 33, 149: 34, 15: 35, 539: 36, 670: 37, 932: 38, 411: 39, 801: 40, 542: 41, 280: 42, 277: 43, 408: 44, 18: 45, 673: 46, 935: 47, 146: 48, 938: 49, 676: 50, 548: 51, 941: 52, 810: 53, 283: 54, 679: 55, 807: 56, 545: 57, 286: 58, 417: 59, 155: 60, 414: 61, 24: 62, 21: 63, 152: 64, 292: 65, 947: 66, 420: 67, 944: 68, 158: 69, 161: 70, 423: 71, 685: 72, 551: 73, 554: 74, 289: 75, 816: 76, 30: 77, 682: 78, 813: 79, 27: 80, 688: 81, 298: 82, 429: 83, 164: 84, 33: 85, 950: 86, 819: 87, 560: 88, 295: 89, 426: 90, 953: 91, 694: 92, 691: 93, 557: 94, 825: 95, 956: 96, 167: 97, 822: 98, 36: 99, 304: 100, 828: 101, 962: 102, 831: 103, 435: 104, 959: 105, 700: 106, 566: 107, 39: 108, 432: 109, 301: 110, 563: 111, 307: 112, 45: 113, 438: 114, 170: 115, 42: 116, 173: 117, 569: 118, 176: 119, 697: 120, 703: 121, 834: 122, 444: 123, 441: 124, 965: 125, 179: 126, 51: 127, 572: 128, 837: 129, 310: 130, 313: 131, 575: 132, 48: 133, 182: 134, 706: 135, 185: 136, 712: 137, 450: 138, 578: 139, 581: 140, 316: 141, 57: 142, 188: 143, 319: 144, 840: 145, 447: 146, 709: 147, 54: 148, 843: 149, 846: 150, 60: 151, 322: 152, 453: 153, 194: 154, 849: 155, 718: 156, 715: 157, 63: 158, 584: 159, 587: 160, 325: 161, 191: 162, 456: 163, 459: 164, 462: 165, 593: 166, 66: 167, 328: 168, 69: 169, 852: 170, 721: 171, 331: 172, 590: 173, 724: 174, 855: 175, 200: 176, 197: 177, 334: 178, 727: 179, 730: 180, 75: 181, 596: 182, 468: 183, 465: 184, 206: 185, 337: 186, 72: 187, 861: 188, 599: 189, 203: 190, 858: 191, 78: 192, 212: 193, 605: 194, 739: 195, 474: 196, 608: 197, 477: 198, 343: 199, 340: 200, 864: 201, 209: 202, 471: 203, 867: 204, 81: 205, 736: 206, 602: 207, 870: 208, 733: 209, 90: 210, 346: 211, 218: 212, 611: 213, 87: 214, 614: 215, 480: 216, 84: 217, 352: 218, 876: 219, 742: 220, 483: 221, 873: 222, 349: 223, 215: 224, 745: 225, 221: 226, 227: 227, 355: 228, 620: 229, 617: 230, 358: 231, 489: 232, 751: 233, 882: 234, 93: 235, 224: 236, 96: 237, 879: 238, 486: 239, 748: 240, 754: 241, 230: 242, 885: 243, 623: 244, 99: 245, 364: 246, 888: 247, 626: 248, 492: 249, 361: 250, 495: 251, 102: 252, 233: 253, 757: 254, 239: 255, 108: 256, 760: 257, 236: 258, 891: 259, 105: 260, 367: 261, 501: 262, 632: 263, 370: 264, 629: 265, 894: 266, 763: 267, 498: 268, 504: 269, 245: 270, 507: 271, 114: 272, 900: 273, 769: 274, 635: 275, 242: 276, 376: 277, 897: 278, 766: 279, 373: 280, 111: 281, 638: 282, 903: 283, 513: 284, 248: 285, 382: 286, 120: 287, 906: 288, 510: 289, 379: 290, 251: 291, 772: 292, 775: 293, 644: 294, 641: 295, 117: 296, 385: 297, 516: 298, 388: 299, 781: 300, 778: 301, 123: 302, 519: 303, 650: 304, 522: 305, 912: 306, 254: 307, 647: 308, 915: 309, 257: 310, 784: 311, 391: 312, 653: 313, 909: 314, 126: 315, 260: 316, 135: 317, 656: 318, 1: 319, 397: 320, 129: 321, 525: 322, 263: 323, 132: 324, 659: 325, 528: 326, 787: 327, 394: 328, 918: 329, 266: 330, 790: 331, 921: 332, 4: 333, 665: 334, 7: 335, 534: 336, 272: 337, 531: 338, 924: 339, 793: 340, 141: 341, 796: 342, 138: 343, 662: 344, 400: 345, 269: 346, 403: 347, 10: 348, 927: 349, 802: 350, 144: 351, 930: 352, 16: 353, 540: 354, 537: 355, 278: 356, 799: 357, 409: 358, 275: 359, 13: 360, 406: 361, 147: 362, 671: 363, 668: 364, 933: 365, 805: 366, 153: 367, 939: 368, 543: 369, 936: 370, 281: 371, 150: 372, 22: 373, 19: 374, 415: 375, 677: 376, 284: 377, 412: 378, 808: 379, 546: 380, 674: 381, 552: 382, 421: 383, 680: 384, 549: 385, 418: 386, 28: 387, 156: 388, 290: 389, 814: 390, 287: 391, 945: 392, 942: 393, 811: 394, 159: 395, 25: 396, 683: 397, 951: 398, 165: 399, 817: 400, 34: 401, 427: 402, 686: 403, 558: 404, 823: 405, 954: 406, 555: 407, 820: 408, 296: 409, 948: 410, 424: 411, 162: 412, 293: 413, 31: 414, 689: 415, 561: 416, 299: 417, 826: 418, 302: 419, 305: 420, 692: 421, 171: 422, 567: 423, 433: 424, 436: 425, 430: 426, 698: 427, 960: 428, 957: 429, 829: 430, 168: 431, 695: 432, 174: 433, 564: 434, 40: 435, 37: 436, 573: 437, 704: 438, 963: 439, 177: 440, 311: 441, 180: 442, 442: 443, 701: 444, 832: 445, 43: 446, 46: 447, 439: 448, 49: 449, 308: 450, 570: 451, 835: 452, 966: 453, 55: 454, 448: 455, 838: 456, 52: 457, 183: 458, 314: 459, 186: 460, 576: 461, 710: 462, 841: 463, 445: 464, 707: 465, 317: 466, 579: 467, 189: 468, 844: 469, 716: 470, 61: 471, 585: 472, 454: 473, 713: 474, 320: 475, 323: 476, 847: 477, 192: 478, 58: 479, 451: 480, 582: 481, 460: 482, 591: 483, 457: 484, 326: 485, 198: 486, 722: 487, 329: 488, 719: 489, 64: 490, 67: 491, 853: 492, 195: 493, 588: 494, 850: 495, 335: 496, 725: 497, 204: 498, 728: 499, 332: 500, 597: 501, 856: 502, 466: 503, 73: 504, 859: 505, 594: 506, 463: 507, 201: 508, 70: 509, 862: 510, 338: 511, 472: 512, 210: 513, 868: 514, 79: 515, 600: 516, 469: 517, 76: 518, 341: 519, 734: 520, 737: 521, 207: 522, 603: 523, 731: 524, 865: 525, 609: 526, 740: 527, 85: 528, 612: 529, 481: 530, 82: 531, 216: 532, 606: 533, 213: 534, 743: 535, 219: 536, 347: 537, 874: 538, 344: 539, 350: 540, 478: 541, 475: 542, 88: 543, 871: 544, 225: 545, 749: 546, 356: 547, 222: 548, 618: 549, 353: 550, 487: 551, 484: 552, 746: 553, 877: 554, 615: 555, 91: 556, 94: 557, 880: 558, 621: 559, 228: 560, 231: 561, 490: 562, 755: 563, 886: 564, 97: 565, 362: 566, 752: 567, 624: 568, 493: 569, 100: 570, 359: 571, 883: 572, 234: 573, 365: 574, 630: 575, 103: 576, 758: 577, 499: 578, 106: 579, 889: 580, 892: 581, 368: 582, 627: 583, 761: 584, 237: 585, 496: 586, 505: 587, 109: 588, 895: 589, 112: 590, 764: 591, 243: 592, 636: 593, 374: 594, 767: 595, 240: 596, 371: 597, 502: 598, 633: 599, 898: 600, 508: 601, 901: 602, 377: 603, 380: 604, 904: 605, 770: 606, 511: 607, 246: 608, 773: 609, 642: 610, 249: 611, 118: 612, 639: 613, 115: 614, 514: 615, 651: 616, 121: 617, 782: 618, 383: 619, 913: 620, 648: 621, 776: 622, 907: 623, 124: 624, 645: 625, 520: 626, 910: 627, 252: 628, 779: 629, 255: 630, 517: 631, 386: 632, 130: 633, 395: 634, 133: 635, 916: 636, 788: 637, 261: 638, 654: 639, 392: 640, 258: 641, 389: 642, 127: 643, 264: 644, 657: 645, 2: 646, 919: 647, 785: 648, 526: 649, 523: 650, 8: 651, 925: 652, 139: 653, 532: 654, 401: 655, 791: 656, 660: 657, 529: 658, 136: 659, 267: 660, 922: 661, 5: 662, 270: 663, 663: 664, 398: 665, 794: 666, 931: 667, 800: 668, 11: 669, 142: 670, 276: 671, 797: 672, 407: 673, 145: 674, 273: 675, 535: 676, 669: 677, 666: 678, 928: 679, 404: 680, 14: 681, 538: 682, 672: 683, 937: 684, 541: 685, 282: 686, 806: 687, 413: 688, 934: 689, 544: 690, 410: 691, 148: 692, 17: 693, 20: 694, 279: 695, 151: 696, 675: 697, 803: 698, 943: 699, 416: 700, 26: 701, 547: 702, 285: 703, 812: 704, 154: 705, 288: 706, 157: 707, 681: 708, 940: 709, 23: 710, 550: 711, 419: 712, 678: 713, 809: 714, 425: 715, 553: 716, 556: 717, 163: 718, 946: 719, 815: 720, 684: 721, 949: 722, 294: 723, 687: 724, 160: 725, 29: 726, 291: 727, 422: 728, 818: 729, 32: 730, 559: 731, 824: 732, 300: 733, 434: 734, 35: 735, 952: 736, 431: 737, 690: 738, 827: 739, 696: 740, 693: 741, 565: 742, 821: 743, 955: 744, 428: 745, 169: 746, 562: 747, 38: 748, 297: 749, 958: 750, 166: 751, 961: 752, 830: 753, 437: 754, 309: 755, 568: 756, 964: 757, 303: 758, 172: 759, 41: 760, 699: 761, 44: 762, 440: 763, 306: 764, 833: 765, 571: 766, 47: 767, 175: 768, 702: 769, 178: 770, 836: 771, 443: 772, 181: 773, 839: 774, 315: 775, 446: 776, 574: 777, 50: 778, 53: 779, 705: 780, 708: 781, 577: 782, 184: 783, 312: 784, 967: 785, 449: 786, 842: 787, 580: 788, 714: 789, 711: 790, 190: 791, 321: 792, 583: 793, 59: 794, 187: 795, 56: 796, 845: 797, 452: 798, 318: 799, 65: 800, 193: 801, 720: 802, 848: 803, 589: 804, 327: 805, 324: 806, 196: 807, 455: 808, 717: 809, 458: 810, 62: 811, 851: 812, 586: 813, 857: 814, 464: 815, 199: 816, 723: 817, 68: 818, 595: 819, 202: 820, 330: 821, 333: 822, 854: 823, 726: 824, 461: 825, 592: 826, 71: 827, 601: 828, 74: 829, 77: 830, 339: 831, 467: 832, 860: 833, 729: 834, 208: 835, 336: 836, 205: 837, 863: 838, 470: 839, 732: 840, 598: 841, 211: 842, 217: 843, 348: 844, 479: 845, 342: 846, 604: 847, 735: 848, 83: 849, 869: 850, 738: 851, 872: 852, 741: 853, 345: 854, 866: 855, 80: 856, 214: 857, 610: 858, 607: 859, 476: 860, 473: 861, 875: 862, 92: 863, 613: 864, 351: 865, 220: 866, 747: 867, 744: 868, 485: 869, 86: 870, 354: 871, 223: 872, 616: 873, 89: 874, 878: 875, 482: 876, 881: 877, 488: 878, 226: 879, 622: 880, 357: 881, 753: 882, 95: 883, 750: 884, 619: 885, 884: 886, 229: 887, 98: 888, 360: 889, 491: 890, 235: 891, 625: 892, 890: 893, 887: 894, 232: 895, 756: 896, 363: 897, 759: 898, 101: 899, 497: 900, 628: 901, 494: 902, 366: 903, 104: 904, 762: 905, 372: 906, 110: 907, 893: 908, 765: 909, 241: 910, 107: 911, 896: 912, 238: 913, 634: 914, 500: 915, 631: 916, 503: 917, 369: 918, 247: 919, 640: 920, 113: 921, 244: 922, 637: 923, 506: 924, 509: 925, 375: 926, 378: 927, 116: 928, 771: 929, 768: 930, 902: 931, 899: 932, 253: 933, 381: 934, 122: 935, 646: 936, 905: 937, 384: 938, 643: 939, 774: 940, 515: 941, 119: 942, 777: 943, 512: 944, 911: 945, 908: 946, 780: 947, 250: 948, 917: 949, 128: 950, 125: 951, 783: 952, 649: 953, 786: 954, 131: 955, 524: 956, 655: 957, 262: 958, 914: 959, 259: 960, 652: 961, 390: 962, 256: 963, 518: 964, 393: 965, 387: 966, 521: 967}\n",
      "_category_mappings[time_id]: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41, 42: 42, 43: 43, 44: 44, 45: 45, 46: 46, 47: 47, 48: 48, 49: 49, 50: 50, 51: 51, 52: 52, 53: 53, 54: 54, 55: 55, 56: 56, 57: 57, 58: 58, 59: 59, 60: 60, 61: 61, 62: 62, 63: 63, 64: 64, 65: 65, 66: 66, 67: 67, 68: 68, 69: 69, 70: 70, 71: 71, 72: 72, 73: 73, 74: 74, 75: 75, 76: 76, 77: 77, 78: 78, 79: 79, 80: 80, 81: 81, 82: 82, 83: 83, 84: 84, 85: 85, 86: 86, 87: 87, 88: 88, 89: 89, 90: 90, 91: 91, 92: 92, 93: 93, 94: 94, 95: 95, 96: 96, 97: 97, 98: 98, 99: 99, 100: 100, 101: 101, 102: 102, 103: 103, 104: 104, 105: 105, 106: 106, 107: 107, 108: 108, 109: 109, 110: 110, 111: 111, 112: 112, 113: 113, 114: 114, 115: 115, 116: 116, 117: 117, 118: 118, 119: 119, 120: 120, 121: 121, 122: 122, 123: 123, 124: 124, 125: 125, 126: 126, 127: 127, 128: 128, 129: 129, 130: 130, 131: 131, 132: 132, 133: 133, 134: 134, 135: 135, 136: 136, 137: 137, 138: 138, 139: 139, 140: 140, 141: 141, 142: 142, 143: 143, 144: 144, 145: 145, 146: 146, 147: 147, 148: 148, 149: 149, 150: 150, 151: 151, 152: 152, 153: 153, 154: 154, 155: 155, 156: 156, 157: 157, 158: 158, 159: 159, 160: 160, 161: 161, 162: 162, 163: 163, 164: 164, 165: 165, 166: 166, 167: 167, 168: 168, 169: 169, 170: 170, 171: 171, 172: 172, 173: 173, 174: 174, 175: 175, 176: 176, 177: 177, 178: 178, 179: 179, 180: 180, 181: 181, 182: 182, 183: 183, 184: 184, 185: 185, 186: 186, 187: 187, 188: 188, 189: 189, 190: 190, 191: 191, 192: 192, 193: 193, 194: 194, 195: 195, 196: 196, 197: 197, 198: 198, 199: 199, 200: 200, 201: 201, 202: 202, 203: 203, 204: 204, 205: 205, 206: 206, 207: 207, 208: 208, 209: 209, 210: 210, 211: 211, 212: 212, 213: 213, 214: 214, 215: 215, 216: 216, 217: 217, 218: 218, 219: 219, 220: 220, 221: 221, 222: 222, 223: 223, 224: 224, 225: 225, 226: 226, 227: 227, 228: 228, 229: 229, 230: 230, 231: 231, 232: 232, 233: 233, 234: 234, 235: 235, 236: 236, 237: 237, 238: 238, 239: 239, 240: 240, 241: 241, 242: 242, 243: 243, 244: 244, 245: 245, 246: 246, 247: 247, 248: 248, 249: 249, 250: 250, 251: 251, 252: 252, 253: 253, 254: 254, 255: 255, 256: 256, 257: 257, 258: 258, 259: 259, 260: 260, 261: 261, 262: 262, 263: 263, 264: 264, 265: 265, 266: 266, 267: 267, 268: 268, 269: 269, 270: 270, 271: 271, 272: 272, 273: 273, 274: 274, 275: 275, 276: 276, 277: 277, 278: 278, 279: 279, 280: 280, 281: 281, 282: 282, 283: 283, 284: 284, 285: 285, 286: 286, 287: 287, 288: 288, 289: 289, 290: 290, 291: 291, 292: 292, 293: 293, 294: 294, 295: 295, 296: 296, 297: 297, 298: 298, 299: 299, 300: 300, 301: 301, 302: 302, 303: 303, 304: 304, 305: 305, 306: 306, 307: 307, 308: 308, 309: 309, 310: 310, 311: 311, 312: 312, 313: 313, 314: 314, 315: 315, 316: 316, 317: 317, 318: 318, 319: 319, 320: 320, 321: 321, 322: 322, 323: 323, 324: 324, 325: 325, 326: 326, 327: 327, 328: 328, 329: 329, 330: 330, 331: 331, 332: 332, 333: 333, 334: 334, 335: 335, 336: 336, 337: 337, 338: 338, 339: 339, 340: 340, 341: 341, 342: 342, 343: 343, 344: 344, 345: 345, 346: 346, 347: 347, 348: 348, 349: 349, 350: 350, 351: 351, 352: 352, 353: 353, 354: 354, 355: 355, 356: 356, 357: 357, 358: 358, 359: 359, 360: 360, 361: 361, 362: 362, 363: 363, 364: 364, 365: 365, 366: 366, 367: 367, 368: 368, 369: 369, 370: 370, 371: 371, 372: 372, 373: 373, 374: 374, 375: 375, 376: 376, 377: 377, 378: 378, 379: 379, 380: 380, 381: 381, 382: 382, 383: 383, 384: 384, 385: 385, 386: 386, 387: 387, 388: 388, 389: 389, 390: 390, 391: 391, 392: 392, 393: 393, 394: 394, 395: 395, 396: 396, 397: 397, 398: 398, 399: 399, 400: 400, 401: 401, 402: 402, 403: 403, 404: 404, 405: 405, 406: 406, 407: 407, 408: 408, 409: 409, 410: 410, 411: 411, 412: 412, 413: 413, 414: 414, 415: 415, 416: 416, 417: 417, 418: 418, 419: 419, 420: 420, 421: 421, 422: 422, 423: 423, 424: 424, 425: 425, 426: 426, 427: 427, 428: 428, 429: 429, 430: 430, 431: 431, 432: 432, 433: 433, 434: 434, 435: 435, 436: 436, 437: 437, 438: 438, 439: 439, 440: 440, 441: 441, 442: 442, 443: 443, 444: 444, 445: 445, 446: 446, 447: 447, 448: 448, 449: 449, 450: 450, 451: 451, 452: 452, 453: 453, 454: 454, 455: 455, 456: 456, 457: 457, 458: 458, 459: 459, 460: 460, 461: 461, 462: 462, 463: 463, 464: 464, 465: 465, 466: 466, 467: 467, 468: 468, 469: 469, 470: 470, 471: 471, 472: 472, 473: 473, 474: 474, 475: 475, 476: 476, 477: 477, 478: 478, 479: 479, 480: 480, 481: 481, 482: 482, 483: 483, 484: 484, 485: 485, 486: 486, 487: 487, 488: 488, 489: 489, 490: 490, 491: 491, 492: 492, 493: 493, 494: 494, 495: 495, 496: 496, 497: 497, 498: 498, 499: 499, 500: 500, 501: 501, 502: 502, 503: 503, 504: 504, 505: 505, 506: 506, 507: 507, 508: 508, 509: 509, 510: 510, 511: 511, 512: 512, 513: 513, 514: 514, 515: 515, 516: 516, 517: 517, 518: 518, 519: 519, 520: 520, 521: 521, 522: 522, 523: 523, 524: 524, 525: 525, 526: 526, 527: 527, 528: 528, 529: 529, 530: 530, 531: 531, 532: 532, 533: 533, 534: 534, 535: 535, 536: 536, 537: 537, 538: 538, 539: 539, 540: 540, 541: 541, 542: 542, 543: 543, 544: 544, 545: 545, 546: 546, 547: 547, 548: 548, 549: 549, 550: 550, 551: 551, 552: 552, 553: 553, 554: 554, 555: 555, 556: 556, 557: 557, 558: 558, 559: 559, 560: 560, 561: 561, 562: 562, 563: 563, 564: 564, 565: 565, 566: 566, 567: 567, 568: 568, 569: 569, 570: 570, 571: 571, 572: 572, 573: 573, 574: 574, 575: 575, 576: 576, 577: 577, 578: 578, 579: 579, 580: 580, 581: 581, 582: 582, 583: 583, 584: 584, 585: 585, 586: 586, 587: 587, 588: 588, 589: 589, 590: 590, 591: 591, 592: 592, 593: 593, 594: 594, 595: 595, 596: 596, 597: 597, 598: 598, 599: 599, 600: 600, 601: 601, 602: 602, 603: 603, 604: 604, 605: 605, 606: 606, 607: 607, 608: 608, 609: 609, 610: 610, 611: 611, 612: 612, 613: 613, 614: 614, 615: 615, 616: 616, 617: 617, 618: 618, 619: 619, 620: 620, 621: 621, 622: 622, 623: 623, 624: 624, 625: 625, 626: 626, 627: 627, 628: 628, 629: 629, 630: 630, 631: 631, 632: 632, 633: 633, 634: 634, 635: 635, 636: 636, 637: 637, 638: 638, 639: 639, 640: 640, 641: 641, 642: 642, 643: 643, 644: 644, 645: 645, 646: 646, 647: 647, 648: 648, 649: 649, 650: 650, 651: 651, 652: 652, 653: 653, 654: 654, 655: 655, 656: 656, 657: 657, 658: 658, 659: 659, 660: 660, 661: 661, 662: 662, 663: 663, 664: 664, 665: 665, 666: 666, 667: 667, 668: 668, 669: 669, 670: 670, 671: 671, 672: 672, 673: 673, 674: 674, 675: 675, 676: 676, 677: 677, 678: 678, 679: 679, 680: 680, 681: 681, 682: 682, 683: 683, 684: 684, 685: 685, 686: 686, 687: 687, 688: 688, 689: 689, 690: 690, 691: 691, 692: 692, 693: 693, 694: 694, 695: 695, 696: 696, 697: 697, 698: 698, 699: 699, 700: 700, 701: 701, 702: 702, 703: 703, 704: 704, 705: 705, 706: 706, 707: 707, 708: 708, 709: 709, 710: 710, 711: 711, 712: 712, 713: 713, 714: 714, 715: 715, 716: 716, 717: 717, 718: 718, 719: 719, 720: 720, 721: 721, 722: 722, 723: 723, 724: 724, 725: 725, 726: 726, 727: 727, 728: 728, 729: 729, 730: 730, 731: 731, 732: 732, 733: 733, 734: 734, 735: 735, 736: 736, 737: 737, 738: 738, 739: 739, 740: 740, 741: 741, 742: 742, 743: 743, 744: 744, 745: 745, 746: 746, 747: 747, 748: 748, 749: 749, 750: 750, 751: 751, 752: 752, 753: 753, 754: 754, 755: 755, 756: 756, 757: 757, 758: 758, 759: 759, 760: 760, 761: 761, 762: 762, 763: 763, 764: 764, 765: 765, 766: 766, 767: 767, 768: 768, 769: 769, 770: 770, 771: 771, 772: 772, 773: 773, 774: 774, 775: 775, 776: 776, 777: 777, 778: 778, 779: 779, 780: 780, 781: 781, 782: 782, 783: 783, 784: 784, 785: 785, 786: 786, 787: 787, 788: 788, 789: 789, 790: 790, 791: 791, 792: 792, 793: 793, 794: 794, 795: 795, 796: 796, 797: 797, 798: 798, 799: 799, 800: 800, 801: 801, 802: 802, 803: 803, 804: 804, 805: 805, 806: 806, 807: 807, 808: 808, 809: 809, 810: 810, 811: 811, 812: 812, 813: 813, 814: 814, 815: 815, 816: 816, 817: 817, 818: 818, 819: 819, 820: 820, 821: 821, 822: 822, 823: 823, 824: 824, 825: 825, 826: 826, 827: 827, 828: 828, 829: 829, 830: 830, 831: 831, 832: 832, 833: 833, 834: 834, 835: 835, 836: 836, 837: 837, 838: 838, 839: 839, 840: 840, 841: 841, 842: 842, 843: 843, 844: 844, 845: 845, 846: 846, 847: 847, 848: 848, 849: 849, 850: 850, 851: 851, 852: 852, 853: 853, 854: 854, 855: 855, 856: 856, 857: 857, 858: 858, 859: 859, 860: 860, 861: 861, 862: 862, 863: 863, 864: 864, 865: 865, 866: 866, 867: 867, 868: 868, 869: 869, 870: 870, 871: 871, 872: 872, 873: 873, 874: 874, 875: 875, 876: 876, 877: 877, 878: 878, 879: 879, 880: 880, 881: 881, 882: 882, 883: 883, 884: 884, 885: 885, 886: 886, 887: 887, 888: 888, 889: 889, 890: 890, 891: 891, 892: 892, 893: 893, 894: 894, 895: 895, 896: 896, 897: 897, 898: 898, 899: 899, 900: 900, 901: 901, 902: 902, 903: 903, 904: 904, 905: 905, 906: 906, 907: 907, 908: 908, 909: 909, 910: 910, 911: 911, 912: 912, 913: 913, 914: 914, 915: 915, 916: 916, 917: 917, 918: 918, 919: 919, 920: 920, 921: 921, 922: 922, 923: 923, 924: 924, 925: 925, 926: 926, 927: 927, 928: 928, 929: 929, 930: 930, 931: 931, 932: 932, 933: 933, 934: 934, 935: 935, 936: 936, 937: 937, 938: 938, 939: 939, 940: 940, 941: 941, 942: 942, 943: 943, 944: 944, 945: 945, 946: 946, 947: 947, 948: 948, 949: 949, 950: 950, 951: 951, 952: 952, 953: 953, 954: 954, 955: 955, 956: 956, 957: 957, 958: 958, 959: 959, 960: 960, 961: 961, 962: 962, 963: 963, 964: 964, 965: 965, 966: 966, 967: 967}\n"
     ]
    }
   ],
   "source": [
    "train_original = pl.scan_parquet(\"/kaggle/input/js24-preprocessing-create-lags/training.parquet\")\n",
    "valid_original = pl.scan_parquet(\"/kaggle/input/js24-preprocessing-create-lags/validation.parquet\")\n",
    "all_original = pl.concat([train_original, valid_original])\n",
    "\n",
    "def get_category_mapping(df, column):\n",
    "    unique_values = df.select([column]).unique().collect().to_series()\n",
    "    return {cat: idx for idx, cat in enumerate(unique_values)}\n",
    "category_mappings = {col: get_category_mapping(all_original, col) for col in feature_cat + ['symbol_id', 'time_id']}\n",
    "\n",
    "_category_mappings = {'feature_09': {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21},\n",
    " 'feature_10': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8},\n",
    " 'feature_11': {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13,\n",
    "  76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30},\n",
    " 'symbol_id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19,\n",
    "  20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38},\n",
    " 'time_id' : {i : i for i in range(968)}}\n",
    "\n",
    "# Compare category_mappings and _category_mappings\n",
    "for key in category_mappings:\n",
    "    if category_mappings[key] != _category_mappings.get(key, {}):\n",
    "        print(f\"Mismatch found in {key}:\")\n",
    "        print(f\"category_mappings[{key}]: {category_mappings[key]}\")\n",
    "        print(f\"_category_mappings[{key}]: {_category_mappings.get(key, {})}\")\n",
    "\n",
    "def encode_column(df, column, mapping):\n",
    "    def encode_category(category):\n",
    "        return mapping.get(category, -1)  \n",
    "    \n",
    "    return df.with_columns(\n",
    "        pl.col(column).map_elements(encode_category, return_dtype=pl.Int16).alias(column)\n",
    "    )\n",
    "\n",
    "for col in feature_cat + ['symbol_id', 'time_id']:\n",
    "    train_original = encode_column(train_original, col, category_mappings[col])\n",
    "    valid_original = encode_column(valid_original, col, category_mappings[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_original \\\n",
    "             .filter((pl.col(\"date_id\") >= start_dt) & (pl.col(\"date_id\") <= end_dt)) \\\n",
    "             .select(feature_train + [target_col, 'weight', 'symbol_id', 'time_id'])\n",
    "\n",
    "train_data2 = valid_original \\\n",
    "             .filter(pl.col(\"date_id\") <= end_dt) \\\n",
    "             .select(feature_train + [target_col, 'weight', 'symbol_id', 'time_id'])\n",
    "\n",
    "train_data = pl.concat([train_data1, train_data2])\n",
    "valid_data = valid_original \\\n",
    "             .filter(pl.col(\"date_id\") > end_dt)\\\n",
    "             .sort(['date_id', 'time_id'])\\\n",
    "             .select(feature_train + [target_col, 'weight', 'symbol_id', 'time_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tensor = torch.tensor(train_data.collect().to_numpy(), dtype=torch.float32)\n",
    "valid_data_tensor = torch.tensor(valid_data.collect().to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(train_data_tensor)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, num_workers=1, pin_memory=False, shuffle=True)\n",
    "valid_ds = TensorDataset(valid_data_tensor)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, num_workers=1, pin_memory=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = False\n",
    "if all_data:\n",
    "    train_ds = ConcatDataset([train_ds, valid_ds])\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, num_workers=4, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cont_features = 85\n",
    "n_cat_features = 5\n",
    "n_classes = None\n",
    "cat_cardinalities = [23, 10, 32, 40, 969]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True, False,  True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins_input = train_data_tensor[:, :-4][:, [col for col in range(train_data_tensor[:, :-4].shape[1]) if col not in [9, 10, 11]]]\n",
    "nan_mask = torch.isnan(bins_input)\n",
    "inf_mask = torch.isinf(bins_input)\n",
    "valid_rows = ~(nan_mask.any(dim=1) | inf_mask.any(dim=1))\n",
    "valid_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins_input_clean = bins_input[valid_rows][:1_000_000]\n",
    "bins = compute_bins(bins_input_clean , n_bins=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parameter_groups(model):\n",
    "    decay = []\n",
    "    no_decay = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # Gradient가 필요 없는 경우 생략\n",
    "        if 'cont_embeddings' in name or 'bias' in name:\n",
    "            # Embedding 레이어와 bias에는 weight decay를 적용하지 않음\n",
    "            no_decay.append(param)\n",
    "        else:\n",
    "            # 나머지 파라미터에는 weight decay 적용\n",
    "            decay.append(param)\n",
    "    return [\n",
    "        {'params': no_decay, 'weight_decay': 0.0},\n",
    "        {'params': decay, 'weight_decay': 5e-3}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_cont_features: int,\n",
    "        cat_cardinalities: list[int],\n",
    "        bins: Optional[list[Tensor]],\n",
    "        mlp_kwargs: dict,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.cat_cardinalities = cat_cardinalities\n",
    "        # The total representation size for categorical features\n",
    "        # == the sum of one-hot representation sizes\n",
    "        # == the sum of the numbers of distinct values of all features.\n",
    "        d_cat = sum(cat_cardinalities)\n",
    "\n",
    "        # Choose any of the embeddings below.\n",
    "\n",
    "        # d_embedding = 24\n",
    "        # self.cont_embeddings = rtdl_num_embeddings.PeriodicEmbeddings(\n",
    "        #     n_cont_features, d_embedding, lite=False\n",
    "        # )\n",
    "        # d_num = n_cont_features * d_embedding\n",
    "\n",
    "        # assert bins is not None\n",
    "        # self.cont_embeddings = rtdl_num_embeddings.PiecewiseLinearEncoding(bins)\n",
    "        # d_num = sum(len(b) - 1 for b in bins)\n",
    "\n",
    "        assert bins is not None\n",
    "        d_embedding = 8\n",
    "        self.cont_embeddings = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "            bins, d_embedding, activation=False, version='B'\n",
    "        )\n",
    "        d_num = n_cont_features * d_embedding\n",
    "\n",
    "        # d_embedding = 32\n",
    "        # self.cont_embeddings = rtdl_num_embeddings.LinearReLUEmbeddings(\n",
    "        #     n_cont_features, d_embedding\n",
    "        # )\n",
    "        # d_num = n_cont_features * d_embedding\n",
    "\n",
    "        self.backbone = rtdl_revisiting_models.MLP(d_in=d_num + d_cat, **mlp_kwargs)\n",
    "\n",
    "    def forward(self, x_cont: Tensor, x_cat: Optional[Tensor]) -> Tensor:\n",
    "        x = []\n",
    "\n",
    "        # Step 1. Embed the continuous features.\n",
    "        # Flattening is needed for MLP-like models.\n",
    "        x.append(self.cont_embeddings(x_cont).flatten(1))\n",
    "\n",
    "        # Step 2. Encode the categorical features using any strategy.\n",
    "        if x_cat is not None:\n",
    "            x.extend(\n",
    "                F.one_hot(column, cardinality)\n",
    "                for column, cardinality in zip(x_cat.T, self.cat_cardinalities)\n",
    "            )\n",
    "\n",
    "        # Step 3. Assemble the vector input for the backbone.\n",
    "        x = torch.column_stack(x)\n",
    "\n",
    "        # Step 4. Apply the backbone.\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = 'regression'\n",
    "model = Model(\n",
    "    n_cont_features=n_cont_features,\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    bins=bins,\n",
    "    mlp_kwargs={        \n",
    "        'n_blocks': 3,\n",
    "        'd_block': 512,\n",
    "        'dropout': 0.25,\n",
    "        'd_out': n_classes if task_type == 'multiclass' else 1,\n",
    "    },\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    # make_parameter_groups(model),\n",
    "    lr=1e-4,\n",
    "    weight_decay=5e-3 ,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2Loss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        mse_loss = torch.sum((y_pred - y_true) ** 2)\n",
    "        var_y = torch.sum(y_true ** 2)\n",
    "        loss = mse_loss / (var_y + 1e-38)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class LogCoshLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogCoshLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = torch.log(torch.cosh(y_pred - y_true))\n",
    "        return torch.mean(loss)\n",
    "# loss_fn = nn.HuberLoss(delta=0.2)\n",
    "loss_fn = R2Loss()\n",
    "# loss_fn = nn.MSELoss()\n",
    "\n",
    "timer = delu.tools.Timer()\n",
    "patience = 10\n",
    "early_stopping = delu.tools.EarlyStopping(patience, mode=\"max\")\n",
    "best = {\n",
    "    \"val\": -math.inf,\n",
    "    \"epoch\": -1,\n",
    "}\n",
    "timer.run()\n",
    "\n",
    "def r2_val(y_true, y_pred, sample_weight):\n",
    "    residuals = sample_weight * (y_true - y_pred) ** 2\n",
    "    weighted_residual_sum = np.sum(residuals)\n",
    "\n",
    "    # Calculate weighted sum of squared true values (denominator)\n",
    "    weighted_true_sum = np.sum(sample_weight * (y_true) ** 2)\n",
    "\n",
    "    # Calculate weighted R2\n",
    "    r2 = 1 - weighted_residual_sum / weighted_true_sum\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export POLARS_ALLOW_FORKING_THREAD=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57250/484766503.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./epoch5_r2_-0.00616002082824707.pt\")['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./epoch5_r2_-0.00616002082824707.pt\")['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5068/5068 [15:56<00:00,  5.30it/s, epoch=1/100, loss=0.898689, lr=1.000e-04]\n",
      "100%|██████████| 56/56 [00:10<00:00,  5.44it/s, epoch=1/100, val_loss=0.965391, lr=1.000e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_r2 = 0.086477, val_loss_mean=1.006547, val_r2=-0.003932, [time] 0:17:08.119499\n",
      "🌸 New best epoch! 🌸\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5068/5068 [14:34<00:00,  5.80it/s, epoch=2/100, loss=0.898070, lr=1.000e-04]\n",
      "100%|██████████| 56/56 [00:08<00:00,  6.48it/s, epoch=2/100, val_loss=0.970950, lr=1.000e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_r2 = 0.098802, val_loss_mean=1.015441, val_r2=-0.011741, [time] 0:31:51.439645\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5068/5068 [13:06<00:00,  6.45it/s, epoch=3/100, loss=0.888762, lr=1.000e-04]\n",
      "100%|██████████| 56/56 [00:09<00:00,  6.00it/s, epoch=3/100, val_loss=0.967405, lr=1.000e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_r2 = 0.107263, val_loss_mean=1.013795, val_r2=-0.010469, [time] 0:45:07.520296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5068/5068 [15:11<00:00,  5.56it/s, epoch=4/100, loss=0.875064, lr=1.000e-04]\n",
      "100%|██████████| 56/56 [00:08<00:00,  6.76it/s, epoch=4/100, val_loss=0.969819, lr=1.000e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_r2 = 0.116200, val_loss_mean=1.016357, val_r2=-0.012468, [time] 1:00:28.167470\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5068/5068 [13:39<00:00,  6.19it/s, epoch=5/100, loss=0.875653, lr=1.000e-04]\n",
      "100%|██████████| 56/56 [00:08<00:00,  6.38it/s, epoch=5/100, val_loss=0.970339, lr=1.000e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_r2 = 0.121376, val_loss_mean=1.023951, val_r2=-0.019078, [time] 1:14:16.529146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5068/5068 [13:31<00:00,  6.25it/s, epoch=6/100, loss=0.875338, lr=1.000e-04]\n",
      "100%|██████████| 56/56 [00:08<00:00,  6.63it/s, epoch=6/100, val_loss=0.974272, lr=1.000e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_r2 = 0.127336, val_loss_mean=1.022680, val_r2=-0.019021, [time] 1:27:56.935064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5068/5068 [12:17<00:00,  6.87it/s, epoch=7/100, loss=0.860172, lr=1.000e-04]\n",
      "100%|██████████| 56/56 [00:07<00:00,  7.05it/s, epoch=7/100, val_loss=0.978605, lr=1.000e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_r2 = 0.133437, val_loss_mean=1.025465, val_r2=-0.021054, [time] 1:40:22.566388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5068/5068 [13:35<00:00,  6.21it/s, epoch=8/100, loss=0.831243, lr=1.000e-04]\n",
      "100%|██████████| 56/56 [00:08<00:00,  6.84it/s, epoch=8/100, val_loss=0.978494, lr=1.000e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_r2 = 0.139032, val_loss_mean=1.023452, val_r2=-0.019344, [time] 1:54:07.105941\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5068 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    train_pred_list = []\n",
    "    with tqdm(train_dl, total=len(train_dl), leave=True) as phar:\n",
    "        i = 0\n",
    "        for train_tensor in phar:\n",
    "            optimizer.zero_grad()\n",
    "            X_input = train_tensor[0][:, :-4].to(device)\n",
    "            y_input = train_tensor[0][:, -4].to(device)\n",
    "            w_input = train_tensor[0][:, -3].to(device)\n",
    "            symbol_input    = train_tensor[0][:, -2].to(device)\n",
    "            time_input      = train_tensor[0][:, -1].to(device)            \n",
    "            x_cont_input = X_input[:, [col for col in range(X_input.shape[1]) if col not in [9, 10, 11]]]\n",
    "\n",
    "            x_cat_input = X_input[:, [9, 10, 11]]\n",
    "            x_cat_input = torch.concat(\n",
    "                [x_cat_input, symbol_input.unsqueeze(-1), time_input.unsqueeze(-1)], axis=1\n",
    "            ).to(torch.int64)\n",
    "\n",
    "            # Replace NaNs/Infs in x_cont_input with 0\n",
    "            x_cont_input = torch.where(torch.isnan(x_cont_input) | torch.isinf(x_cont_input), torch.tensor(0.0, device=x_cont_input.device), x_cont_input)\n",
    "            output = model(x_cont_input, x_cat_input).squeeze(-1)\n",
    "            loss = loss_fn(output, y_input)\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(\n",
    "                model.parameters(), \n",
    "                clip_value=1.0,\n",
    "            )\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                train_pred_list.append((output, y_input, w_input))\n",
    "                phar.set_postfix(\n",
    "                    OrderedDict(\n",
    "                        epoch=f'{epoch + 1}/{num_epochs}',\n",
    "                        loss=f'{loss.item():.6f}',\n",
    "                        lr=f'{optimizer.param_groups[0][\"lr\"]:.3e}'\n",
    "                    )\n",
    "                )\n",
    "            phar.update(1)\n",
    "            i += 1\n",
    "\n",
    "    weights_train = torch.cat([x[2] for x in train_pred_list]).cpu().numpy()\n",
    "    y_train = torch.cat([x[1] for x in train_pred_list]).cpu().numpy()\n",
    "    prob_train = torch.cat([x[0] for x in train_pred_list]).detach().cpu().numpy()\n",
    "    train_r2 = r2_val(y_train, prob_train, weights_train)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss_list = []\n",
    "    valid_pred_list = []\n",
    "    with tqdm(valid_dl, total=len(valid_dl), leave=True) as phar:\n",
    "        for valid_tensor in phar:\n",
    "            X_valid = valid_tensor[0][:, :-4].to(device)\n",
    "            y_valid = valid_tensor[0][:, -4].to(device)\n",
    "            w_valid = valid_tensor[0][:, -3].to(device)\n",
    "            symbol_valid = valid_tensor[0][:, -2].to(device)\n",
    "            time_valid = valid_tensor[0][:, -1].to(device)\n",
    "            \n",
    "            x_cont_valid = X_valid[:, [col for col in range(X_valid.shape[1]) if col not in [9, 10, 11]]]\n",
    "            x_cont_valid = torch.where(\n",
    "                torch.isnan(x_cont_valid) | torch.isinf(x_cont_valid),\n",
    "                torch.tensor(0.0, device=x_cont_valid.device), \n",
    "            x_cont_valid)\n",
    "            \n",
    "            x_cat_valid = X_valid[:, [9, 10, 11]]\n",
    "            x_cat_valid = (torch.concat(\n",
    "                [x_cat_valid, symbol_valid.unsqueeze(-1),time_valid.unsqueeze(-1)], axis=1)\n",
    "            ).to(torch.int64)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(x_cont_valid, x_cat_valid).squeeze(-1)\n",
    "\n",
    "            val_loss = loss_fn(y_pred, y_valid)\n",
    "            valid_loss_list.append(val_loss)\n",
    "            valid_pred_list.append((y_pred, y_valid, w_valid))\n",
    "            phar.set_postfix(\n",
    "                OrderedDict(\n",
    "                    epoch=f'{epoch + 1}/{num_epochs}',\n",
    "                    val_loss=f'{val_loss.item():.6f}',\n",
    "                    lr=f'{optimizer.param_groups[0][\"lr\"]:.3e}'\n",
    "                )\n",
    "            )\n",
    "            phar.update(1)\n",
    "            i += 1\n",
    "\n",
    "        valid_loss_mean = sum(valid_loss_list) / len(valid_loss_list)\n",
    "        weights_eval = torch.cat([x[2] for x in valid_pred_list]).cpu().numpy()\n",
    "        y_eval = torch.cat([x[1] for x in valid_pred_list]).cpu().numpy()\n",
    "        prob_eval = torch.cat([x[0] for x in valid_pred_list]).cpu().numpy()\n",
    "        val_r2 = r2_val(y_eval, prob_eval, weights_eval)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: train_r2 = {train_r2:.6f}, val_loss_mean={valid_loss_mean:.6f}, val_r2={val_r2:.6f}, [time] {timer}\")\n",
    "\n",
    "        if val_r2 > best[\"val\"]:\n",
    "            print(\"🌸 New best epoch! 🌸\")\n",
    "            best = {\"val\": val_r2, \"epoch\": epoch}\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'r2': val_r2,\n",
    "        }\n",
    "        torch.save(checkpoint, f'epoch{epoch}_r2_{val_r2}.pt')\n",
    "    print()\n",
    "    early_stopping.update(val_r2)\n",
    "    if early_stopping.should_stop():\n",
    "        print(\"Early stop\")\n",
    "        break\n",
    "\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'r2': val_r2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
