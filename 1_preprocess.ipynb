{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "class CONFIG:\n",
    "    path_str = \"/kaggle/input/jane-street-realtime-marketdata-forecasting/train.parquet\"\n",
    "    target_col = \"responder_6\"\n",
    "    lag_cols_original = [\"date_id\", \"symbol_id\"] + [f\"responder_{idx}\" for idx in range(9)]\n",
    "    lag_cols_rename = { f\"responder_{idx}\" : f\"responder_{idx}_lag_1\" for idx in range(9)}\n",
    "    valid_ratio = 0.01\n",
    "    start_dt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use last 2 parquets\n",
    "train = pl.scan_parquet(\n",
    "    CONFIG.path_str\n",
    ").select(\n",
    "    pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"id\"),\n",
    "    pl.all(),\n",
    ").with_columns(\n",
    "    (pl.col(CONFIG.target_col)).cast(pl.Int32).alias(\"label\"),\n",
    ").filter(\n",
    "    pl.col(\"date_id\").gt(CONFIG.start_dt)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = train.select(pl.col(CONFIG.lag_cols_original))\n",
    "lags = lags.rename(CONFIG.lag_cols_rename)\n",
    "lags = lags.with_columns(\n",
    "    date_id = pl.col('date_id') + 1,  # lagged by 1 day\n",
    ")\n",
    "lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()  # pick up last record of previous date\n",
    "train = train.join(lags, on=[\"date_id\", \"symbol_id\"],  how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory (os error 2): /kaggle/input/jane-street-realtime-marketdata-forecasting/train.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'select'\n\t[3] 'with_columns'\n\t[4] 'filter'\n\t[5] 'join left'\n\t[6] 'join'\n\t[7] 'select'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 전체 훈련 샘플 수를 \"date_id\" 열을 선택하고 행을 카운트하여 계산\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m len_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 검증 비율에 기반하여 검증에 사용할 레코드 수 결정\u001b[39;00m\n\u001b[1;32m      4\u001b[0m valid_records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(len_train \u001b[38;5;241m*\u001b[39m CONFIG\u001b[38;5;241m.\u001b[39mvalid_ratio)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/polars/lazyframe/frame.py:2057\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, _type_check, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _check_order, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory (os error 2): /kaggle/input/jane-street-realtime-marketdata-forecasting/train.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'select'\n\t[3] 'with_columns'\n\t[4] 'filter'\n\t[5] 'join left'\n\t[6] 'join'\n\t[7] 'select'\n"
     ]
    }
   ],
   "source": [
    "# 전체 훈련 샘플 수를 \"date_id\" 열을 선택하고 행을 카운트하여 계산\n",
    "len_train = train.select(pl.col(\"date_id\")).collect().shape[0]\n",
    "# 검증 비율에 기반하여 검증에 사용할 레코드 수 결정\n",
    "valid_records = int(len_train * CONFIG.valid_ratio)\n",
    "# 오프라인 모델(훈련)에 사용할 레코드 수 계산\n",
    "len_ofl_mdl = len_train - valid_records\n",
    "# 계산된 인덱스에서 date_id를 선택하여 오프라인 훈련 세트의 마지막 date_id 가져오기\n",
    "last_tr_dt = train.select(pl.col(\"date_id\")).collect().row(len_ofl_mdl)[0]\n",
    "# 전체 훈련 샘플 수 출력\n",
    "print(f\"\\n len_train = {len_train}\")\n",
    "# 검증 레코드 수 출력\n",
    "print(f\"\\n len_ofl_mdl = {len_ofl_mdl}\")\n",
    "# 마지막 오프라인 훈련 날짜 출력\n",
    "print(f\"\\n---> Last offline train date = {last_tr_dt}\\n\")\n",
    "training_data = train.filter(pl.col(\"date_id\").le(last_tr_dt))\n",
    "validation_data   = train.filter(pl.col(\"date_id\").gt(last_tr_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_data\u001b[49m\u001b[38;5;241m.\u001b[39mcollect()\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      2\u001b[0m write_parquet(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/js24-preprocessing-create-lags/training.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, partition_by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m validation_data\u001b[38;5;241m.\u001b[39mcollect()\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      6\u001b[0m write_parquet(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/js24-preprocessing-create-lags/validation.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, partition_by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "training_data.collect().\\\n",
    "write_parquet(\n",
    "    f\"/kaggle/input/js24-preprocessing-create-lags/training.parquet\", partition_by = \"date_id\",\n",
    ")\n",
    "validation_data.collect().\\\n",
    "write_parquet(\n",
    "    f\"/kaggle/input/js24-preprocessing-create-lags/validation.parquet\", partition_by = \"date_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2573/1252290557.py:6: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  feature_cols = [col for col in train.columns if col not in ['date_id', 'symbol_id', 'id', 'label']]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory (os error 2): /kaggle/input/jane-street-realtime-marketdata-forecasting/train.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'select'\n\t[3] 'with_columns'\n\t[4] 'filter'\n\t[5] 'join left'\n\t[6] 'join'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# List of feature columns excluding non-feature columns\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Compute means and standard deviations using Polars\u001b[39;00m\n\u001b[1;32m      9\u001b[0m means \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mselect(feature_cols)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mcollect()\u001b[38;5;241m.\u001b[39mto_dicts()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/polars/lazyframe/frame.py:460\u001b[0m, in \u001b[0;36mLazyFrame.columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03mGet the column names.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m['foo', 'bar']\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m issue_warning(\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetermining the column names of a LazyFrame requires resolving its schema,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to get the column names without this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m     category\u001b[38;5;241m=\u001b[39mPerformanceWarning,\n\u001b[1;32m    459\u001b[0m )\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnames()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/polars/lazyframe/frame.py:2277\u001b[0m, in \u001b[0;36mLazyFrame.collect_schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Schema:\n\u001b[1;32m   2248\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2249\u001b[0m \u001b[38;5;124;03m    Resolve the schema of this LazyFrame.\u001b[39;00m\n\u001b[1;32m   2250\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Schema(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, check_dtypes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory (os error 2): /kaggle/input/jane-street-realtime-marketdata-forecasting/train.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'select'\n\t[3] 'with_columns'\n\t[4] 'filter'\n\t[5] 'join left'\n\t[6] 'join'\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "import joblib\n",
    "\n",
    "# List of feature columns excluding non-feature columns\n",
    "feature_cols = [col for col in train.columns if col not in ['date_id', 'symbol_id', 'id', 'label']]\n",
    "\n",
    "# Compute means and standard deviations using Polars\n",
    "means = train.select(feature_cols).mean().collect().to_dicts()[0]\n",
    "stds = train.select(feature_cols).std().collect().to_dicts()[0]\n",
    "\n",
    "data_stats = {'mean': means, 'std': stds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/jane-street-data-preprocessing/data_stats.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the stats using joblib\n",
    "import os\n",
    "os.makedirs(\"/kaggle/input/jane-street-data-preprocessing\", exist_ok=True)\n",
    "joblib.dump(data_stats, \"/kaggle/input/jane-street-data-preprocessing/data_stats.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
