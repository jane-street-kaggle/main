{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63672a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T22:32:36.560056Z",
     "start_time": "2025-01-04T22:32:35.832279Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-04T23:05:06.507005Z",
     "iopub.status.busy": "2025-01-04T23:05:06.506738Z",
     "iopub.status.idle": "2025-01-04T23:05:10.258971Z",
     "shell.execute_reply": "2025-01-04T23:05:10.258052Z"
    },
    "papermill": {
     "duration": 3.757545,
     "end_time": "2025-01-04T23:05:10.260539",
     "exception": false,
     "start_time": "2025-01-04T23:05:06.502994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "IS_INFERENCE = True  # 이 값으로 학습/추론 모드 결정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b76195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T22:32:36.566161Z",
     "start_time": "2025-01-04T22:32:36.564010Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-04T23:05:10.267456Z",
     "iopub.status.busy": "2025-01-04T23:05:10.267081Z",
     "iopub.status.idle": "2025-01-04T23:05:10.270567Z",
     "shell.execute_reply": "2025-01-04T23:05:10.269658Z"
    },
    "papermill": {
     "duration": 0.008044,
     "end_time": "2025-01-04T23:05:10.271881",
     "exception": false,
     "start_time": "2025-01-04T23:05:10.263837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_DIR = '/kaggle/input/nn-linear-regression-l2-models/linear_regression_nn_l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdf23dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T22:32:36.622006Z",
     "start_time": "2025-01-04T22:32:36.620422Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-04T23:05:10.277624Z",
     "iopub.status.busy": "2025-01-04T23:05:10.277412Z",
     "iopub.status.idle": "2025-01-04T23:05:10.281387Z",
     "shell.execute_reply": "2025-01-04T23:05:10.280631Z"
    },
    "papermill": {
     "duration": 0.008074,
     "end_time": "2025-01-04T23:05:10.282504",
     "exception": false,
     "start_time": "2025-01-04T23:05:10.274430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_r2_score(y_true, y_pred, weights):\n",
    "    \"\"\"\n",
    "    Calculate weighted R² score\n",
    "    R² = 1 - Σ wᵢ(yᵢ - ŷᵢ)² / Σ wᵢyᵢ²\n",
    "    \"\"\"\n",
    "    numerator = torch.sum(weights * (y_true - y_pred) ** 2)\n",
    "    denominator = torch.sum(weights * y_true ** 2)\n",
    "    r2 = 1 - numerator / denominator\n",
    "    return r2.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ae021c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T22:32:36.668851Z",
     "start_time": "2025-01-04T22:32:36.659936Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-04T23:05:10.288172Z",
     "iopub.status.busy": "2025-01-04T23:05:10.287945Z",
     "iopub.status.idle": "2025-01-04T23:05:10.294019Z",
     "shell.execute_reply": "2025-01-04T23:05:10.293393Z"
    },
    "papermill": {
     "duration": 0.010146,
     "end_time": "2025-01-04T23:05:10.295198",
     "exception": false,
     "start_time": "2025-01-04T23:05:10.285052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    train_mean = None\n",
    "    train_std = None\n",
    "\n",
    "    def __init__(self, df, is_test=False):\n",
    "        features = df.select([f\"feature_{i:02d}\" for i in range(79)]).fill_null(0).to_numpy()\n",
    "\n",
    "        if not is_test:\n",
    "            # 학습 데이터일 경우 평균과 표준편차를 계산하여 저장\n",
    "            StockDataset.train_mean = np.mean(features, axis=0)\n",
    "            StockDataset.train_std = np.std(features, axis=0)\n",
    "\n",
    "            # 학습 시에는 평균과 표준편차도 저장\n",
    "            np.save(f'{BASE_MODEL_DIR}/train_mean.npy', StockDataset.train_mean)\n",
    "            np.save(f'{BASE_MODEL_DIR}/train_std.npy', StockDataset.train_std)\n",
    "        else:\n",
    "            # 추론 시에는 저장된 평균과 표준편차를 로드\n",
    "            StockDataset.train_mean = np.load(f'{BASE_MODEL_DIR}/train_mean.npy')\n",
    "            StockDataset.train_std = np.load(f'{BASE_MODEL_DIR}/train_std.npy')\n",
    "\n",
    "        # 표준화\n",
    "        self.features = (features - StockDataset.train_mean) / StockDataset.train_std\n",
    "        self.features = torch.FloatTensor(self.features)\n",
    "\n",
    "        self.weights = torch.FloatTensor(df.select([\"weight\"]).to_numpy())\n",
    "\n",
    "        if not is_test:\n",
    "            self.target = torch.FloatTensor(df.select([\"responder_6\"]).to_numpy())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if hasattr(self, 'target'):\n",
    "            return self.features[idx], self.target[idx], self.weights[idx]\n",
    "        return self.features[idx], torch.zeros(1), self.weights[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266af5bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T22:32:36.714987Z",
     "start_time": "2025-01-04T22:32:36.712754Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-04T23:05:10.300795Z",
     "iopub.status.busy": "2025-01-04T23:05:10.300595Z",
     "iopub.status.idle": "2025-01-04T23:05:10.304589Z",
     "shell.execute_reply": "2025-01-04T23:05:10.303997Z"
    },
    "papermill": {
     "duration": 0.007949,
     "end_time": "2025-01-04T23:05:10.305633",
     "exception": false,
     "start_time": "2025-01-04T23:05:10.297684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, l2_lambda=0.01):  # L2 정규화 강도 설정\n",
    "        super().__init__()\n",
    "        self.l2_lambda = l2_lambda\n",
    "\n",
    "    def forward(self, pred, target, weights, model):\n",
    "        # 기본 MSE 손실\n",
    "        mse_loss = torch.mean(weights * (pred - target) ** 2)\n",
    "\n",
    "        # L2 정규화: 모든 가중치의 제곱합\n",
    "        l2_loss = sum(p.pow(2).sum() for p in model.parameters())\n",
    "\n",
    "        # 최종 손실 = MSE + λ||w||²\n",
    "        return mse_loss + self.l2_lambda * l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c607e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T22:32:36.766405Z",
     "start_time": "2025-01-04T22:32:36.760150Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-04T23:05:10.311168Z",
     "iopub.status.busy": "2025-01-04T23:05:10.310952Z",
     "iopub.status.idle": "2025-01-04T23:05:10.314385Z",
     "shell.execute_reply": "2025-01-04T23:05:10.313773Z"
    },
    "papermill": {
     "duration": 0.007363,
     "end_time": "2025-01-04T23:05:10.315499",
     "exception": false,
     "start_time": "2025-01-04T23:05:10.308136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eab3d71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T22:32:36.957728Z",
     "start_time": "2025-01-04T22:32:36.833585Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-04T23:05:10.321102Z",
     "iopub.status.busy": "2025-01-04T23:05:10.320866Z",
     "iopub.status.idle": "2025-01-04T23:05:10.329102Z",
     "shell.execute_reply": "2025-01-04T23:05:10.328481Z"
    },
    "papermill": {
     "duration": 0.012172,
     "end_time": "2025-01-04T23:05:10.330172",
     "exception": false,
     "start_time": "2025-01-04T23:05:10.318000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    print(\"Training started...\")\n",
    "\n",
    "    # 학습 기록을 저장할 리스트\n",
    "    losses = []\n",
    "    r2_scores = []\n",
    "\n",
    "    # 결과 저장할 디렉토리 생성\n",
    "    import os\n",
    "    os.makedirs('training_plots', exist_ok=True)\n",
    "\n",
    "    # 플롯 설정\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        all_targets = []\n",
    "        all_outputs = []\n",
    "        all_weights = []\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "        for batch_features, batch_targets, batch_weights in progress_bar:\n",
    "            batch_features = batch_features.to(device)\n",
    "            batch_targets = batch_targets.to(device)\n",
    "            batch_weights = batch_weights.to(device)\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_targets, batch_weights, model)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_targets.append(batch_targets)\n",
    "            all_outputs.append(outputs)\n",
    "            all_weights.append(batch_weights)\n",
    "\n",
    "            progress_bar.set_postfix({'batch_loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        # Calculate metrics\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        y_true = torch.cat(all_targets)\n",
    "        y_pred = torch.cat(all_outputs)\n",
    "        weights = torch.cat(all_weights)\n",
    "        r2 = weighted_r2_score(y_true, y_pred, weights)\n",
    "\n",
    "        # 기록 저장\n",
    "        losses.append(avg_loss)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        # Loss 플롯\n",
    "        ax1.clear()\n",
    "        ax1.plot(losses, 'b-')\n",
    "        ax1.set_title('Training Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # R² 점수 플롯\n",
    "        ax2.clear()\n",
    "        ax2.plot(r2_scores, 'r-')\n",
    "        ax2.set_title('R² Score')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('R²')\n",
    "        ax2.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 현재 에폭의 그래프를 파일로 저장\n",
    "        plt.savefig(f'training_plots/epoch_{epoch+1:03d}.png')\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, R² Score: {r2:.4f}')\n",
    "        print('-' * 50)\n",
    "\n",
    "    # 최종 결과를 CSV 파일로 저장\n",
    "    import pandas as pd\n",
    "    results_df = pd.DataFrame({\n",
    "        'epoch': range(1, num_epochs + 1),\n",
    "        'loss': losses,\n",
    "        'r2_score': r2_scores\n",
    "    })\n",
    "    results_df.to_csv(f'{BASE_MODEL_DIR}/training_results.csv', index=False)\n",
    "\n",
    "    print(\"Training completed. Results saved to 'training_results.csv'\")\n",
    "    print(f\"Training plots saved in 'training_plots' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62dead04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T22:32:36.969340Z",
     "start_time": "2025-01-04T22:32:36.967249Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-04T23:05:10.335666Z",
     "iopub.status.busy": "2025-01-04T23:05:10.335467Z",
     "iopub.status.idle": "2025-01-04T23:05:10.341275Z",
     "shell.execute_reply": "2025-01-04T23:05:10.340646Z"
    },
    "papermill": {
     "duration": 0.009835,
     "end_time": "2025-01-04T23:05:10.342442",
     "exception": false,
     "start_time": "2025-01-04T23:05:10.332607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lags_: pl.DataFrame | None = None\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None = None) -> pl.DataFrame:\n",
    "    \"\"\"Competition prediction function\"\"\"\n",
    "    global model  # PyTorch 모델\n",
    "    global lags_\n",
    "\n",
    "    # 원본 row_id 저장\n",
    "    row_ids = test['row_id'].to_numpy()\n",
    "\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    # 데이터셋 생성\n",
    "    test_dataset = StockDataset(test, is_test=True)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=4096,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 모델 예측\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, _, _ in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            features = features.to(device)\n",
    "            outputs = model(features)\n",
    "            predictions.append(outputs.cpu())\n",
    "\n",
    "    # 예측값을 numpy array로 변환\n",
    "    predictions = torch.cat(predictions).numpy()\n",
    "    predictions = np.clip(predictions, -5, 5)\n",
    "\n",
    "    # 결과 DataFrame 생성\n",
    "    result = pl.DataFrame({\n",
    "        'row_id': row_ids,\n",
    "        'responder_6': predictions.flatten()  # 2D array를 1D로 변환\n",
    "    })\n",
    "\n",
    "    print(\"Prediction completed.\")\n",
    "    print(result)\n",
    "    print(result.shape)\n",
    "\n",
    "    # Validation checks\n",
    "    assert isinstance(result, (pl.DataFrame, pd.DataFrame))\n",
    "    assert result.columns == ['row_id', 'responder_6']\n",
    "    assert len(result) == len(test)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218114b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T23:00:12.774795Z",
     "start_time": "2025-01-04T22:32:37.028557Z"
    },
    "execution": {
     "iopub.execute_input": "2025-01-04T23:05:10.347993Z",
     "iopub.status.busy": "2025-01-04T23:05:10.347782Z",
     "iopub.status.idle": "2025-01-04T23:05:11.158681Z",
     "shell.execute_reply": "2025-01-04T23:05:11.157633Z"
    },
    "papermill": {
     "duration": 0.814932,
     "end_time": "2025-01-04T23:05:11.159846",
     "exception": false,
     "start_time": "2025-01-04T23:05:10.344914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-ee0541662ce7>:25: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  self.weights = torch.FloatTensor(df.select([\"weight\"]).to_numpy())\n",
      "Predicting: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed.\n",
      "shape: (39, 2)\n",
      "┌────────┬─────────────┐\n",
      "│ row_id ┆ responder_6 │\n",
      "│ ---    ┆ ---         │\n",
      "│ i64    ┆ f32         │\n",
      "╞════════╪═════════════╡\n",
      "│ 0      ┆ 0.020922    │\n",
      "│ 1      ┆ 0.020922    │\n",
      "│ 2      ┆ 0.020922    │\n",
      "│ 3      ┆ 0.020922    │\n",
      "│ 4      ┆ 0.020922    │\n",
      "│ …      ┆ …           │\n",
      "│ 34     ┆ 0.020922    │\n",
      "│ 35     ┆ 0.020922    │\n",
      "│ 36     ┆ 0.020922    │\n",
      "│ 37     ┆ 0.020922    │\n",
      "│ 38     ┆ 0.020922    │\n",
      "└────────┴─────────────┘\n",
      "(39, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not IS_INFERENCE:\n",
    "    # 학습 모드\n",
    "    # 데이터 로드 및 데이터셋 생성\n",
    "    train = pl.read_parquet('kaggle/data/train.parquet')\n",
    "    dataset = StockDataset(train)\n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=4096,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 모델 초기화\n",
    "    input_dim = 79\n",
    "    model = LinearRegression(input_dim).to(device)\n",
    "    criterion = WeightedMSELoss(l2_lambda=0.01)  # L2 정규화 파라미터 설정\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "    # 모델 학습\n",
    "    num_epochs = 5\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "    # 모델 저장\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, f'{BASE_MODEL_DIR}/linear_regression_nn.pth')\n",
    "    print(f\"Model saved to '{BASE_MODEL_DIR}/linear_regression_nn.pth'\")\n",
    "\n",
    "else:\n",
    "    # 추론 모드\n",
    "    # 모델 로드\n",
    "    input_dim = 79\n",
    "    model = LinearRegression(input_dim).to(device)\n",
    "    checkpoint = torch.load(f'{BASE_MODEL_DIR}/linear_regression_nn.pth', weights_only=True)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    if IS_KAGGLE:\n",
    "        import kaggle_evaluation.jane_street_inference_server\n",
    "\n",
    "        inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "        if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "            inference_server.serve()\n",
    "        else:\n",
    "            inference_server.run_local_gateway(\n",
    "                (\n",
    "                    '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
    "                    '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        test = pl.read_parquet('kaggle/data/test.parquet')\n",
    "        lags = pl.read_parquet('kaggle/data/lags.parquet')\n",
    "        predict(test, lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a2f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T23:00:12.972148Z",
     "start_time": "2025-01-04T23:00:12.970875Z"
    },
    "papermill": {
     "duration": 0.002707,
     "end_time": "2025-01-04T23:05:11.165745",
     "exception": false,
     "start_time": "2025-01-04T23:05:11.163038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "datasetId": 6425776,
     "sourceId": 10373497,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.911944,
   "end_time": "2025-01-04T23:05:12.287463",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-04T23:05:04.375519",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
