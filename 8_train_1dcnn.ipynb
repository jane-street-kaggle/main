{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e958012cc8606e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T07:08:21.373114Z",
     "start_time": "2025-01-10T07:08:20.626469Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6414bbb8-d7f0-4ba7-9f99-e349a4ae48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_numerical_features: int,\n",
    "                 hidden_size: int = 1024,\n",
    "                 n_target: int = 1,\n",
    "                 channel_1: int = 64,\n",
    "                 channel_2: int = 128,\n",
    "                 kernel_size: int = 5,\n",
    "                 dropout_rate: float = 0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size  # Store hidden_size as an instance variable\n",
    "\n",
    "        # 1. Expand 단계: Dense 레이어\n",
    "        self.expand = nn.Sequential(\n",
    "            nn.LayerNorm(num_numerical_features),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_numerical_features, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=hidden_size // 16, \n",
    "                out_channels=channel_1, \n",
    "                kernel_size=kernel_size, \n",
    "                stride=1, \n",
    "                padding=kernel_size // 2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # 3. Conv 블록 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=channel_1, \n",
    "                out_channels=channel_2, \n",
    "                kernel_size=kernel_size, \n",
    "                stride=1, \n",
    "                padding=kernel_size // 2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.AdaptiveAvgPool1d(output_size=16)\n",
    "        )\n",
    "\n",
    "        # 4. Flatten and Dense\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(channel_2 * 16, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(640, n_target)\n",
    "        )\n",
    "\n",
    "        # 추가된 Tanh\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    # Start of Selection\n",
    "    def forward(self, x):\n",
    "        x = self.expand(x)\n",
    "        batch_size = x.size(0)\n",
    "        seq_length = x.size(1) // (self.hidden_size // 16)\n",
    "        x = x.view(batch_size, self.hidden_size // 16, seq_length)\n",
    "\n",
    "        # Conv block 1 with residual connection\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        if x.size() == residual.size():\n",
    "            x = x + residual\n",
    "\n",
    "        # Conv block 2 with residual connection\n",
    "        residual = x\n",
    "        x = self.conv2(x)\n",
    "        if x.size() == residual.size():\n",
    "            x = x + residual\n",
    "\n",
    "        # Flatten and Dense\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = 5 * self.tanh(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee7e46a66e4c424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T07:08:21.502341Z",
     "start_time": "2025-01-10T07:08:21.499862Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_mse_loss(y_true, y_pred, weights):\n",
    "    \"\"\"\n",
    "    Multi-target weighted MSE loss\n",
    "\n",
    "    Args:\n",
    "        y_true: target values (batch_size, n_targets)\n",
    "        y_pred: predicted values (batch_size, n_targets)\n",
    "        weights: weights for each target (batch_size, n_targets)\n",
    "    \"\"\"\n",
    "    return torch.mean(weights * (y_true - y_pred)**2)\n",
    "\n",
    "def weighted_r2_score(y_true, y_pred, weights):\n",
    "    \"\"\"\n",
    "    Multi-target weighted R2 score\n",
    "\n",
    "    Args:\n",
    "        y_true: target values (batch_size, n_targets)\n",
    "        y_pred: predicted values (batch_size, n_targets)\n",
    "        weights: weights for each target (batch_size, n_targets)\n",
    "\n",
    "    Returns:\n",
    "        weighted R2 score (scalar)\n",
    "    \"\"\"\n",
    "    # Ensure inputs are on CPU and converted to numpy\n",
    "    y_true = y_true.detach().cpu().numpy()\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    weights = weights.detach().cpu().numpy()\n",
    "\n",
    "    weights = np.repeat(weights, y_true.shape[1], axis=1)\n",
    "\n",
    "    # print(y_true.shape, y_pred.shape, weights.shape)\n",
    "    # Calculate weighted means for each target\n",
    "    weighted_mean = np.average(y_true, weights=weights, axis=0)\n",
    "\n",
    "    # Calculate total sum of squares\n",
    "    total_ss = np.sum(weights * (y_true - weighted_mean) ** 2, axis=0)\n",
    "\n",
    "    # Calculate residual sum of squares\n",
    "    residual_ss = np.sum(weights * (y_true - y_pred) ** 2, axis=0)\n",
    "\n",
    "    # Calculate R2 score for each target\n",
    "    r2_scores = 1 - (residual_ss / total_ss)\n",
    "\n",
    "    # Return mean R2 score across all targets\n",
    "    return np.mean(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70674ae941a64fe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T07:08:21.433171Z",
     "start_time": "2025-01-10T07:08:21.429338Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, numerical_columns, target_columns, weight_columns=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: pandas DataFrame containing all features\n",
    "            numerical_columns: list of column names for numerical features\n",
    "            target_columns: list of target column names\n",
    "            weight_columns: list of weight column names (optional)\n",
    "        \"\"\"\n",
    "        self.numerical_features = torch.FloatTensor(data[numerical_columns].values)\n",
    "        self.symbol = torch.LongTensor(data['symbol_id'].values)\n",
    "        self.feature_09 = torch.LongTensor(data['feature_09'].values)\n",
    "        self.feature_10 = torch.LongTensor(data['feature_10'].values)\n",
    "        self.feature_11 = torch.LongTensor(data['feature_11'].values)\n",
    "        self.time = torch.LongTensor(data['time_id'].values)\n",
    "\n",
    "        # Multi-target 처리\n",
    "        self.targets = torch.FloatTensor(data[target_columns].values)\n",
    "\n",
    "        # 가중치 처리 (옵션)\n",
    "        if weight_columns:\n",
    "            self.weights = torch.FloatTensor(data[weight_columns].values)\n",
    "        else:\n",
    "            self.weights = torch.ones_like(self.targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'numerical_features': self.numerical_features[idx],\n",
    "            'symbol_id': self.symbol[idx],\n",
    "            'feature_09': self.feature_09[idx],\n",
    "            'feature_10': self.feature_10[idx],\n",
    "            'feature_11': self.feature_11[idx],\n",
    "            'time_id': self.time[idx],\n",
    "            'targets': self.targets[idx],\n",
    "            'weights': self.weights[idx]\n",
    "        }\n",
    "\n",
    "def create_data_loaders(train_data, valid_data, numerical_columns,\n",
    "                        target_columns, weight_columns=None,\n",
    "                        batch_size=256, num_workers=1):\n",
    "    \"\"\"\n",
    "    데이터로더를 생성하는 함수\n",
    "\n",
    "    Args:\n",
    "        train_data: 학습 데이터가 담긴 DataFrame\n",
    "        valid_data: 검증 데이터가 담긴 DataFrame\n",
    "        numerical_columns: 수치형 특성들의 컬럼명 리스트\n",
    "        target_columns: 타겟 변수들의 컬럼명 리스트\n",
    "        weight_columns: 가중치 컬럼명 리스트 (옵션)\n",
    "        batch_size: 배치 크기\n",
    "        num_workers: 데이터 로딩에 사용할 워커 수\n",
    "    \"\"\"\n",
    "\n",
    "    # Dataset 객체 생성\n",
    "    train_dataset = CustomDataset(train_data, numerical_columns, target_columns, weight_columns)\n",
    "    valid_dataset = CustomDataset(valid_data, numerical_columns, target_columns, weight_columns)\n",
    "\n",
    "    # DataLoader 생성\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_r2 = 0\n",
    "    num_batches = len(train_loader)\n",
    "\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"Training Batches\")):\n",
    "        numerical_features = batch['numerical_features'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "        weights = batch['weights'].to(device)\n",
    "        outputs = model(numerical_features)\n",
    "        loss = weighted_mse_loss(targets, outputs, weights)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            r2 = weighted_r2_score(targets, outputs, weights)\n",
    "            total_r2 += r2\n",
    "\n",
    "        # 배치별 진행상황 출력 (10배치마다)\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            avg_loss = total_loss / (batch_idx + 1)\n",
    "            avg_r2 = total_r2 / (batch_idx + 1)\n",
    "            print(f'Batch [{batch_idx+1}/{num_batches}] Loss: {avg_loss:.4f}, R2: {avg_r2:.4f}')\n",
    "\n",
    "    return total_loss / num_batches, total_r2 / num_batches\n",
    "\n",
    "def validate(model, valid_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_r2 = 0\n",
    "    num_batches = len(valid_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(valid_loader):\n",
    "            numerical_features = batch['numerical_features'].to(device)\n",
    "            feature_09 = batch['feature_09'].to(device)\n",
    "            feature_10 = batch['feature_10'].to(device)\n",
    "            feature_11 = batch['feature_11'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            weights = batch['weights'].to(device)\n",
    "\n",
    "            outputs = model(numerical_features)\n",
    "\n",
    "            loss = weighted_mse_loss(targets, outputs, weights)\n",
    "            r2 = weighted_r2_score(targets, outputs, weights)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_r2 += r2\n",
    "\n",
    "        if (batch_idx + 1) % 1000 == 0:\n",
    "            avg_loss = total_loss / (batch_idx + 1)\n",
    "            avg_r2 = total_r2 / (batch_idx + 1)\n",
    "            print(f'Batch [{batch_idx+1}/{num_batches}] Loss: {avg_loss:.4f}, R2: {avg_r2:.4f}')\n",
    "        \n",
    "    return total_loss / num_batches, total_r2 / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef27647920443fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T07:08:30.651969Z",
     "start_time": "2025-01-10T07:08:21.557543Z"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "train = pl.scan_parquet(\"/kaggle/input/js24-preprocessing-create-lags/training.parquet\").collect()\n",
    "valid = pl.scan_parquet(\"/kaggle/input/js24-preprocessing-create-lags/validation.parquet\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38009203f70d09a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T07:08:37.258361Z",
     "start_time": "2025-01-10T07:08:37.256584Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "feature_train_list = [f\"feature_{idx:02d}\" for idx in range(79)] \n",
    "target_col = \"responder_6\"\n",
    "feature_train = feature_train_list + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "\n",
    "feature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\n",
    "feature_cont = [item for item in feature_train if item not in feature_cat]\n",
    "std_feature = [i for i in feature_train_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "data_stats = joblib.load(\"/kaggle/input/jane-street-data-preprocessing/data_stats.pkl\")\n",
    "means = data_stats['mean']\n",
    "stds = data_stats['std']\n",
    "\n",
    "def standardize(df, feature_cols, means, stds):\n",
    "    return df.with_columns([\n",
    "        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n",
    "    ])\n",
    "\n",
    "numerical_columns = feature_train + ['date_id', 'symbol_id', 'time_id']\n",
    "target_columns = ['responder_6'] # 예측할 타겟들\n",
    "weight_columns = ['weight']  # 각 타겟에 대한 가중치 (옵션)\n",
    "\n",
    "train = standardize(train, numerical_columns, means, stds).to_pandas()\n",
    "valid = standardize(valid, numerical_columns, means, stds).to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9052491a271b379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T07:08:44.314990Z",
     "start_time": "2025-01-10T07:08:44.302666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5cb1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "valid = valid.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c465a6c15ed71f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T07:24:31.912968Z",
     "start_time": "2025-01-10T07:24:25.714920Z"
    }
   },
   "outputs": [],
   "source": [
    "# 컬럼 정의\n",
    "# 데이터로더 생성\n",
    "train_loader, valid_loader = create_data_loaders(\n",
    "    train_data=train,\n",
    "    valid_data=valid,\n",
    "    numerical_columns=numerical_columns,\n",
    "    target_columns=target_columns,\n",
    "    weight_columns=weight_columns,\n",
    "    batch_size=2048 * 4,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b3c0aa9c23428d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T07:24:32.122034Z",
     "start_time": "2025-01-10T07:24:32.112746Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = CNN1DModel(\n",
    "    num_numerical_features=len(numerical_columns),\n",
    "    n_target=len(target_columns),\n",
    "    dropout_rate=0.4\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e82deb40bf6cbb45",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-10T07:24:39.966268Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   0%|          | 0/4212 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   2%|▏         | 99/4212 [00:22<15:57,  4.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [100/4212] Loss: 1.2434, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   5%|▍         | 200/4212 [00:44<14:28,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [200/4212] Loss: 1.2391, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   7%|▋         | 299/4212 [01:06<14:04,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [300/4212] Loss: 1.2387, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   9%|▉         | 399/4212 [01:28<14:20,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [400/4212] Loss: 1.2378, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  12%|█▏        | 499/4212 [01:49<13:28,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [500/4212] Loss: 1.2388, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  14%|█▍        | 600/4212 [02:11<13:06,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [600/4212] Loss: 1.2388, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  17%|█▋        | 699/4212 [02:33<12:47,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [700/4212] Loss: 1.2391, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  19%|█▉        | 801/4212 [02:55<11:42,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [800/4212] Loss: 1.2392, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  21%|██▏       | 900/4212 [03:19<12:54,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [900/4212] Loss: 1.2393, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  24%|██▎       | 1000/4212 [03:41<10:54,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1000/4212] Loss: 1.2395, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  26%|██▌       | 1100/4212 [04:04<11:21,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1100/4212] Loss: 1.2393, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  28%|██▊       | 1200/4212 [04:27<11:02,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1200/4212] Loss: 1.2394, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  31%|███       | 1299/4212 [04:50<11:04,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1300/4212] Loss: 1.2380, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  33%|███▎      | 1400/4212 [05:13<11:26,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1400/4212] Loss: 1.2376, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  36%|███▌      | 1500/4212 [05:36<09:34,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1500/4212] Loss: 1.2378, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  38%|███▊      | 1600/4212 [06:00<10:20,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1600/4212] Loss: 1.2376, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  40%|████      | 1700/4212 [06:22<09:07,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1700/4212] Loss: 1.2374, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  43%|████▎     | 1800/4212 [06:44<09:01,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1800/4212] Loss: 1.2372, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  45%|████▌     | 1900/4212 [07:05<08:02,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1900/4212] Loss: 1.2376, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  47%|████▋     | 2000/4212 [07:28<08:32,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2000/4212] Loss: 1.2374, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  50%|████▉     | 2100/4212 [07:51<08:18,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2100/4212] Loss: 1.2372, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  52%|█████▏    | 2200/4212 [08:14<08:01,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2200/4212] Loss: 1.2372, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  55%|█████▍    | 2301/4212 [08:37<06:24,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2300/4212] Loss: 1.2373, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  57%|█████▋    | 2400/4212 [09:00<07:39,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2400/4212] Loss: 1.2375, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  59%|█████▉    | 2500/4212 [09:23<06:18,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2500/4212] Loss: 1.2373, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  62%|██████▏   | 2599/4212 [09:45<06:18,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2600/4212] Loss: 1.2371, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  64%|██████▍   | 2700/4212 [10:08<05:25,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2700/4212] Loss: 1.2372, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  66%|██████▋   | 2799/4212 [10:32<06:08,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2800/4212] Loss: 1.2372, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  69%|██████▉   | 2900/4212 [10:55<04:57,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2900/4212] Loss: 1.2372, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  71%|███████   | 2999/4212 [11:17<04:54,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3000/4212] Loss: 1.2373, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  74%|███████▎  | 3100/4212 [11:40<04:30,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3100/4212] Loss: 1.2371, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  76%|███████▌  | 3200/4212 [12:03<03:48,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3200/4212] Loss: 1.2373, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  78%|███████▊  | 3300/4212 [12:27<03:27,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3300/4212] Loss: 1.2373, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  81%|████████  | 3400/4212 [12:50<02:44,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3400/4212] Loss: 1.2374, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  83%|████████▎ | 3499/4212 [13:13<02:49,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3500/4212] Loss: 1.2374, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  85%|████████▌ | 3600/4212 [13:37<02:16,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3600/4212] Loss: 1.2373, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  88%|████████▊ | 3700/4212 [13:59<02:02,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3700/4212] Loss: 1.2374, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  90%|█████████ | 3799/4212 [14:22<01:40,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3800/4212] Loss: 1.2375, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  93%|█████████▎| 3901/4212 [14:45<01:02,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3900/4212] Loss: 1.2375, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  95%|█████████▍| 3999/4212 [15:17<00:51,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [4000/4212] Loss: 1.2372, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  97%|█████████▋| 4101/4212 [15:40<00:23,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [4100/4212] Loss: 1.2371, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|█████████▉| 4200/4212 [16:03<00:02,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [4200/4212] Loss: 1.2372, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 4212/4212 [16:07<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:\n",
      "Train Loss: 1.2372, Train R2: 0.0002\n",
      "Valid Loss: 0.9191, Valid R2: 0.0011\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   2%|▏         | 101/4212 [00:24<15:04,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [100/4212] Loss: 1.2332, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   5%|▍         | 201/4212 [00:48<15:41,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [200/4212] Loss: 1.2365, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   7%|▋         | 299/4212 [01:11<16:28,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [300/4212] Loss: 1.2397, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   9%|▉         | 400/4212 [01:35<13:54,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [400/4212] Loss: 1.2375, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  12%|█▏        | 500/4212 [01:59<14:34,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [500/4212] Loss: 1.2360, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  14%|█▍        | 600/4212 [02:22<15:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [600/4212] Loss: 1.2353, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  17%|█▋        | 701/4212 [02:46<13:16,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [700/4212] Loss: 1.2353, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  19%|█▉        | 800/4212 [03:10<13:39,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [800/4212] Loss: 1.2358, R2: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  21%|██▏       | 901/4212 [03:33<11:51,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [900/4212] Loss: 1.2363, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  24%|██▍       | 1001/4212 [03:57<12:14,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1000/4212] Loss: 1.2361, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  26%|██▌       | 1100/4212 [04:20<12:44,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1100/4212] Loss: 1.2365, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  28%|██▊       | 1199/4212 [04:44<12:21,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1200/4212] Loss: 1.2363, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  31%|███       | 1299/4212 [05:07<12:17,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1300/4212] Loss: 1.2362, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  33%|███▎      | 1401/4212 [05:32<10:28,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1400/4212] Loss: 1.2362, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  36%|███▌      | 1501/4212 [05:57<10:13,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1500/4212] Loss: 1.2357, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  38%|███▊      | 1600/4212 [06:24<10:29,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1600/4212] Loss: 1.2356, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  40%|████      | 1700/4212 [06:49<09:42,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1700/4212] Loss: 1.2353, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  43%|████▎     | 1800/4212 [07:14<09:17,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1800/4212] Loss: 1.2352, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  45%|████▌     | 1900/4212 [07:40<09:42,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1900/4212] Loss: 1.2355, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  47%|████▋     | 2000/4212 [08:05<09:55,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2000/4212] Loss: 1.2358, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  50%|████▉     | 2101/4212 [08:31<07:50,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2100/4212] Loss: 1.2359, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  52%|█████▏    | 2201/4212 [08:56<07:49,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2200/4212] Loss: 1.2357, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  55%|█████▍    | 2300/4212 [09:21<07:35,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2300/4212] Loss: 1.2356, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  57%|█████▋    | 2400/4212 [09:46<07:02,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2400/4212] Loss: 1.2357, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  59%|█████▉    | 2501/4212 [10:12<06:35,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2500/4212] Loss: 1.2357, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  62%|██████▏   | 2600/4212 [10:37<06:18,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2600/4212] Loss: 1.2357, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  64%|██████▍   | 2701/4212 [11:03<05:57,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2700/4212] Loss: 1.2356, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  66%|██████▋   | 2800/4212 [11:29<06:08,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2800/4212] Loss: 1.2353, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  69%|██████▉   | 2900/4212 [11:54<05:29,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2900/4212] Loss: 1.2352, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  71%|███████   | 3000/4212 [12:19<05:17,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3000/4212] Loss: 1.2351, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  74%|███████▎  | 3099/4212 [12:45<04:55,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3100/4212] Loss: 1.2354, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  76%|███████▌  | 3200/4212 [13:10<03:38,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3200/4212] Loss: 1.2354, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  78%|███████▊  | 3301/4212 [13:35<03:14,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3300/4212] Loss: 1.2355, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  81%|████████  | 3400/4212 [14:00<03:13,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3400/4212] Loss: 1.2354, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  83%|████████▎ | 3500/4212 [14:26<03:01,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3500/4212] Loss: 1.2356, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  85%|████████▌ | 3599/4212 [14:51<02:52,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3600/4212] Loss: 1.2356, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  88%|████████▊ | 3700/4212 [15:17<02:13,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3700/4212] Loss: 1.2354, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  90%|█████████ | 3800/4212 [15:42<01:39,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3800/4212] Loss: 1.2355, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  93%|█████████▎| 3900/4212 [16:07<01:22,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [3900/4212] Loss: 1.2354, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  95%|█████████▍| 4000/4212 [16:32<00:45,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [4000/4212] Loss: 1.2354, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  97%|█████████▋| 4100/4212 [16:58<00:25,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [4100/4212] Loss: 1.2353, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|█████████▉| 4200/4212 [17:23<00:03,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [4200/4212] Loss: 1.2352, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 4212/4212 [17:27<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:\n",
      "Train Loss: 1.2352, Train R2: 0.0002\n",
      "Valid Loss: 0.9194, Valid R2: 0.0002\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   2%|▏         | 100/4212 [00:26<15:13,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [100/4212] Loss: 1.2334, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   5%|▍         | 200/4212 [00:52<17:29,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [200/4212] Loss: 1.2363, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   7%|▋         | 300/4212 [01:17<14:11,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [300/4212] Loss: 1.2313, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   9%|▉         | 400/4212 [01:42<16:15,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [400/4212] Loss: 1.2315, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  12%|█▏        | 500/4212 [02:08<16:26,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [500/4212] Loss: 1.2340, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  14%|█▍        | 600/4212 [02:33<13:01,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [600/4212] Loss: 1.2350, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  17%|█▋        | 700/4212 [02:58<13:12,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [700/4212] Loss: 1.2350, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  19%|█▉        | 800/4212 [03:21<13:59,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [800/4212] Loss: 1.2350, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  21%|██▏       | 900/4212 [03:44<13:14,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [900/4212] Loss: 1.2350, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  24%|██▎       | 999/4212 [04:06<12:39,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1000/4212] Loss: 1.2341, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  26%|██▌       | 1101/4212 [04:29<10:29,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1100/4212] Loss: 1.2340, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  28%|██▊       | 1200/4212 [04:51<11:35,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1200/4212] Loss: 1.2340, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  31%|███       | 1300/4212 [05:15<10:10,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1300/4212] Loss: 1.2340, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  33%|███▎      | 1400/4212 [05:38<11:17,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1400/4212] Loss: 1.2335, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  36%|███▌      | 1500/4212 [06:02<10:48,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1500/4212] Loss: 1.2331, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  38%|███▊      | 1601/4212 [06:28<09:15,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1600/4212] Loss: 1.2323, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  40%|████      | 1700/4212 [06:53<09:35,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1700/4212] Loss: 1.2326, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  43%|████▎     | 1800/4212 [07:17<09:30,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1800/4212] Loss: 1.2326, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  45%|████▌     | 1900/4212 [07:43<08:29,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [1900/4212] Loss: 1.2328, R2: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  47%|████▋     | 1959/4212 [07:57<09:14,  4.06it/s]"
     ]
    }
   ],
   "source": [
    " # 학습 루프 수정\n",
    "num_epochs = 100\n",
    "import os\n",
    "os.makedirs('/kaggle/working', exist_ok=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay = 5e-4)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    torch.save(model.state_dict(), f'/kaggle/working/exported_1dcnn_model_{epoch+1}.pth')\n",
    "    train_loss, train_r2 = train_epoch(model, train_loader, optimizer, device)\n",
    "    valid_loss, valid_r2 = validate(model, valid_loader, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train R2: {train_r2:.4f}')\n",
    "    print(f'Valid Loss: {valid_loss:.4f}, Valid R2: {valid_r2:.4f}')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005dd1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/exported_1dcnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "    global model\n",
    "    global device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.load_state_dict(torch.load('/kaggle/working/exported_1dcnn_model.pth', map_location=device,weights_only= True))\n",
    "    model.eval() \n",
    "\n",
    "    global numerical_columns\n",
    "    sel_cols = numerical_columns\n",
    "    missing_cols = set(sel_cols) - set(test.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns in test data: {missing_cols}\")\n",
    "\n",
    "    test_features = test.select(sel_cols)\n",
    "    test_features = test_features.fill_null(strategy='forward').fill_null(0)\n",
    "    test_features = standardize(test_features,sel_cols, means,stds)\n",
    "    X_test = test_features.to_numpy()\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        predictions = outputs.squeeze().cpu().numpy()\n",
    "    predictions_df = pl.DataFrame({\n",
    "        'row_id': test['row_id'],\n",
    "        'responder_6': predictions\n",
    "    })\n",
    "    assert isinstance(predictions_df, (pl.DataFrame, pd.DataFrame))\n",
    "    assert predictions_df.columns == ['row_id', 'responder_6']\n",
    "    assert len(predictions_df) == len(test)\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import kaggle_evaluation.jane_street_inference_server\n",
    "\n",
    "\n",
    "inference_server = \\\n",
    "kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-realtime-marketdata-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-realtime-marketdata-forecasting/lags.parquet',\n",
    "        )\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
