{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TabNet-Training: Attentive Interpretable Tabular Learning\n",
    "https://www.kaggle.com/code/i2nfinit3y/jane-street-tabm-ft-transformer-training/notebook\n",
    "\n",
    "# TabNet-Inference\n",
    "https://www.kaggle.com/code/i2nfinit3y/jane-street-tabm-ft-transformer-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import rtdl_num_embeddings\n",
    "from rtdl_num_embeddings import compute_bins\n",
    "import rtdl_revisiting_models\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, ConcatDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import delu\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple\n",
    "\n",
    "import joblib\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_list = [f\"feature_{idx:02d}\" for idx in range(79) if idx != 61]\n",
    "\n",
    "target_col = \"responder_6\" \n",
    "\n",
    "feature_test = feature_list \\\n",
    "                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "\n",
    "feature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\n",
    "feature_cont = [item for item in feature_test if item not in feature_cat]\n",
    "\n",
    "batch_size = 8192\n",
    "\n",
    "std_feature = [i for i in feature_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "data_stats = joblib.load(\"/kaggle/input/jane-street-data-preprocessing/data_stats.pkl\")\n",
    "means = data_stats['mean']\n",
    "stds = data_stats['std']\n",
    "\n",
    "def standardize(df, feature_cols, means, stds):\n",
    "    return df.with_columns([\n",
    "        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "feature_train_list = [f\"feature_{idx:02d}\" for idx in range(79)] \n",
    "target_col = \"responder_6\"\n",
    "feature_train = feature_train_list \\\n",
    "                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "\n",
    "start_dt = 110\n",
    "end_dt = 1577\n",
    "\n",
    "feature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\n",
    "feature_cont = [item for item in feature_train if item not in feature_cat]\n",
    "std_feature = [i for i in feature_train_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "batch_size = 8192\n",
    "num_epochs = 100\n",
    "\n",
    "data_stats = joblib.load(\"/kaggle/input/jane-street-data-preprocessing/data_stats.pkl\")\n",
    "means = data_stats['mean']\n",
    "stds = data_stats['std']\n",
    "\n",
    "def standardize(df, feature_cols, means, stds):\n",
    "    return df.with_columns([\n",
    "        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = pl.scan_parquet(\"/kaggle/input/js24-preprocessing-create-lags/training.parquet\")\n",
    "valid_original = pl.scan_parquet(\"/kaggle/input/js24-preprocessing-create-lags/validation.parquet\")\n",
    "all_original = pl.concat([train_original, valid_original])\n",
    "\n",
    "def get_category_mapping(df, column):\n",
    "    unique_values = df.select([column]).unique().collect().to_series()\n",
    "    return {cat: idx for idx, cat in enumerate(unique_values)}\n",
    "category_mappings = {col: get_category_mapping(all_original, col) for col in feature_cat + ['symbol_id', 'time_id']}\n",
    "\n",
    "def encode_column(df, column, mapping):\n",
    "    def encode_category(category):\n",
    "        return mapping.get(category, -1)  \n",
    "    \n",
    "    return df.with_columns(\n",
    "        pl.col(column).map_elements(encode_category, return_dtype=pl.Int16).alias(column)\n",
    "    )\n",
    "\n",
    "for col in feature_cat + ['symbol_id', 'time_id']:\n",
    "    train_original = encode_column(train_original, col, category_mappings[col])\n",
    "    valid_original = encode_column(valid_original, col, category_mappings[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_original \\\n",
    "             .filter((pl.col(\"date_id\") >= start_dt) & (pl.col(\"date_id\") <= end_dt)) \\\n",
    "             .select(feature_train + [target_col, 'weight', 'symbol_id', 'time_id'])\n",
    "\n",
    "train_data2 = valid_original \\\n",
    "             .filter(pl.col(\"date_id\") <= end_dt) \\\n",
    "             .select(feature_train + [target_col, 'weight', 'symbol_id', 'time_id'])\n",
    "\n",
    "train_data = pl.concat([train_data1, train_data2])\n",
    "valid_data = valid_original \\\n",
    "             .filter(pl.col(\"date_id\") > end_dt)\\\n",
    "             .sort(['date_id', 'time_id'])\\\n",
    "             .select(feature_train + [target_col, 'weight', 'symbol_id', 'time_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tensor = torch.tensor(train_data.collect().to_numpy(), dtype=torch.float32)\n",
    "valid_data_tensor = torch.tensor(valid_data.collect().to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(train_data_tensor)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, num_workers=1, pin_memory=False, shuffle=True)\n",
    "valid_ds = TensorDataset(valid_data_tensor)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, num_workers=1, pin_memory=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cont_features = 85\n",
    "n_cat_features = 5\n",
    "n_classes = None\n",
    "cat_cardinalities = [23, 10, 32, 40, 969]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True, False,  True])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins_input = train_data_tensor[:, :-4][:, [col for col in range(train_data_tensor[:, :-4].shape[1]) if col not in [9, 10, 11]]]\n",
    "nan_mask = torch.isnan(bins_input)\n",
    "inf_mask = torch.isinf(bins_input)\n",
    "valid_rows = ~(nan_mask.any(dim=1) | inf_mask.any(dim=1))\n",
    "valid_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins_input_clean = bins_input[valid_rows][:1_000_000]\n",
    "bins = compute_bins(bins_input_clean , n_bins=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_cont_features: int,\n",
    "        cat_cardinalities: list[int],\n",
    "        bins: Optional[list[Tensor]],\n",
    "        mlp_kwargs: dict,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.cat_cardinalities = cat_cardinalities\n",
    "        # The total representation size for categorical features\n",
    "        # == the sum of one-hot representation sizes\n",
    "        # == the sum of the numbers of distinct values of all features.\n",
    "        d_cat = sum(cat_cardinalities)\n",
    "\n",
    "        # Choose any of the embeddings below.\n",
    "\n",
    "        # d_embedding = 24\n",
    "        # self.cont_embeddings = rtdl_num_embeddings.PeriodicEmbeddings(\n",
    "        #     n_cont_features, d_embedding, lite=False\n",
    "        # )\n",
    "        # d_num = n_cont_features * d_embedding\n",
    "\n",
    "        # assert bins is not None\n",
    "        # self.cont_embeddings = rtdl_num_embeddings.PiecewiseLinearEncoding(bins)\n",
    "        # d_num = sum(len(b) - 1 for b in bins)\n",
    "\n",
    "        assert bins is not None\n",
    "        d_embedding = 8\n",
    "        self.cont_embeddings = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
    "            bins, d_embedding, activation=False, version='B'\n",
    "        )\n",
    "        d_num = n_cont_features * d_embedding\n",
    "\n",
    "        # d_embedding = 32\n",
    "        # self.cont_embeddings = rtdl_num_embeddings.LinearReLUEmbeddings(\n",
    "        #     n_cont_features, d_embedding\n",
    "        # )\n",
    "        # d_num = n_cont_features * d_embedding\n",
    "\n",
    "        self.backbone = rtdl_revisiting_models.MLP(d_in=d_num + d_cat, **mlp_kwargs)\n",
    "\n",
    "    def forward(self, x_cont: Tensor, x_cat: Optional[Tensor]) -> Tensor:\n",
    "        x = []\n",
    "\n",
    "        # Step 1. Embed the continuous features.\n",
    "        # Flattening is needed for MLP-like models.\n",
    "        x.append(self.cont_embeddings(x_cont).flatten(1))\n",
    "\n",
    "        # Step 2. Encode the categorical features using any strategy.\n",
    "        if x_cat is not None:\n",
    "            x.extend(\n",
    "                F.one_hot(column, cardinality)\n",
    "                for column, cardinality in zip(x_cat.T, self.cat_cardinalities)\n",
    "            )\n",
    "\n",
    "        # Step 3. Assemble the vector input for the backbone.\n",
    "        x = torch.column_stack(x)\n",
    "\n",
    "        # Step 4. Apply the backbone.\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128753/259952401.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./import-tabm-inference/epoch0_r2_0.004429519176483154.pt\")['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_type = 'regression'\n",
    "model = Model(\n",
    "    n_cont_features=n_cont_features,\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    bins=bins,\n",
    "    mlp_kwargs={        \n",
    "        'n_blocks': 3,\n",
    "        'd_block': 512,\n",
    "        'dropout': 0.25,\n",
    "        'd_out': n_classes if task_type == 'multiclass' else 1,\n",
    "    },\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"./import-tabm-inference/epoch0_r2_0.004429519176483154.pt\")['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_ : pl.DataFrame | None = None\n",
    "\n",
    "lags_history = None\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_, lags_history\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "    for col in feature_cat + ['symbol_id', 'time_id']:\n",
    "        test = encode_column(test, col, category_mappings[col])\n",
    "    predictions = test.select('row_id', pl.lit(0.0).alias('responder_6'))\n",
    "    symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n",
    "    time_id = test.select(\"time_id\").to_numpy()[0]\n",
    "    timie_id_array = test.select(\"time_id\").to_numpy()[:, 0]\n",
    "    \n",
    "    if time_id == 0:\n",
    "        lags = lags.with_columns(pl.col('time_id').cast(pl.Int64))\n",
    "        lags = lags.with_columns(pl.col('symbol_id').cast(pl.Int64))\n",
    "        lags_history = lags\n",
    "        lags = lags.filter(pl.col(\"time_id\") == 0)\n",
    "        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "    else:\n",
    "        lags = lags_history.filter(pl.col(\"time_id\") == time_id)\n",
    "        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "\n",
    "    test = test.with_columns([\n",
    "        pl.col(col).fill_null(0) for col in feature_list + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "    ])\n",
    "    test = standardize(test, std_feature, means, stds)\n",
    "    X_test = test[feature_test].to_numpy()\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    symbol_tensor = torch.tensor(symbol_ids, dtype=torch.float32).to(device)\n",
    "    time_tensor = torch.tensor(timie_id_array, dtype=torch.float32).to(device)\n",
    "    X_cat = X_test_tensor[:, [9, 10, 11]]\n",
    "    X_cont = X_test_tensor[:, [i for i in range(X_test_tensor.shape[1]) if i not in [9, 10, 11]]]\n",
    "    X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1), time_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_cont, X_cat)\n",
    "        # Assuming the model outputs a tensor of shape (batch_size, 1)\n",
    "        preds = outputs.squeeze(-1).cpu().numpy()\n",
    "        preds = preds.mean(1)\n",
    "    predictions = \\\n",
    "    test.select('row_id').\\\n",
    "    with_columns(\n",
    "        pl.Series(\n",
    "            name   = 'responder_6', \n",
    "            values = np.clip(preds, a_min = -5, a_max = 5),\n",
    "            dtype  = pl.Float64,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The predict function must return a DataFrame\n",
    "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
    "    # with columns 'row_id', 'responer_6'\n",
    "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
    "    # and as many rows as the test data.\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export POLARS_ALLOW_FORKING_THREAD=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128753/3458241196.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./import-tabm-inference/epoch0_r2_0.004429519176483154.pt\")['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./import-tabm-inference/epoch0_r2_0.004429519176483154.pt\")['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import polars as pl\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_from = 1577 # for private you should change to 1455 (1 year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4532176"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltraindata = pl.scan_parquet(\"/kaggle/input/jane-street-realtime-marketdata-forecasting/train.parquet\")\n",
    "valid_df = alltraindata.filter(pl.col(\"date_id\")>=valid_from).collect()\n",
    "valid_df = valid_df.with_columns(\n",
    "    pl.Series(range(len(valid_df))).alias(\"row_id\"),\n",
    "    pl.lit(True).alias(\"is_scored\")\n",
    ")\n",
    "len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.write_parquet(\"valid_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 85)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>is_scored</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>&hellip;</th><th>feature_42</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>feature_47</th><th>feature_48</th><th>feature_49</th><th>feature_50</th><th>feature_51</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th></tr><tr><td>i64</td><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>bool</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>3.169998</td><td>true</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>-0.0</td><td>null</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>&hellip;</td><td>null</td><td>-0.0</td><td>null</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>-0.0</td><td>null</td><td>-0.0</td><td>0.0</td><td>null</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td></tr><tr><td>1</td><td>0</td><td>0</td><td>1</td><td>2.165993</td><td>true</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>null</td><td>-0.0</td><td>null</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>&hellip;</td><td>null</td><td>-0.0</td><td>null</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>-0.0</td><td>null</td><td>-0.0</td><td>0.0</td><td>null</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>2</td><td>0</td><td>0</td><td>2</td><td>3.06555</td><td>true</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>-0.0</td><td>null</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>&hellip;</td><td>null</td><td>-0.0</td><td>null</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>-0.0</td><td>null</td><td>-0.0</td><td>0.0</td><td>null</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>-0.0</td><td>-0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 85)\n",
       "┌────────┬─────────┬─────────┬───────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ row_id ┆ date_id ┆ time_id ┆ symbol_id ┆ … ┆ feature_75 ┆ feature_76 ┆ feature_77 ┆ feature_78 │\n",
       "│ ---    ┆ ---     ┆ ---     ┆ ---       ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│ i64    ┆ i16     ┆ i16     ┆ i8        ┆   ┆ f32        ┆ f32        ┆ f32        ┆ f32        │\n",
       "╞════════╪═════════╪═════════╪═══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 0      ┆ 0       ┆ 0       ┆ 0         ┆ … ┆ 0.0        ┆ 0.0        ┆ -0.0       ┆ -0.0       │\n",
       "│ 1      ┆ 0       ┆ 0       ┆ 1         ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.0        ┆ 0.0        │\n",
       "│ 2      ┆ 0       ┆ 0       ┆ 2         ┆ … ┆ 0.0        ┆ 0.0        ┆ -0.0       ┆ -0.0       │\n",
       "└────────┴─────────┴─────────┴───────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = pl.read_parquet(\"/kaggle/input/jane-street-realtime-marketdata-forecasting/test.parquet/date_id=0/part-0.parquet\")\n",
    "test_sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_sample = pl.read_parquet(\"/kaggle/input/jane-street-realtime-marketdata-forecasting/lags.parquet/date_id=0/part-0.parquet\")\n",
    "train_sample = pl.read_parquet(\"/kaggle/input/jane-street-realtime-marketdata-forecasting/train.parquet/partition_id=0/part-0.parquet\",n_rows=1)\n",
    "responder_cols = [s for s in train_sample.columns if \"responder\" in s]\n",
    "\n",
    "def makelag(date_id):\n",
    "    \"\"\"\n",
    "    Making lag at the previout day\n",
    "\n",
    "    Args:\n",
    "    date_id (int): date_id at the previout day\n",
    "    \n",
    "    Returns:\n",
    "    pl.dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    lag = alltraindata.filter(pl.col(\"date_id\")==date_id).select([\"date_id\",\"time_id\",\"symbol_id\"] + responder_cols).collect()\n",
    "    lag.columns = lag_sample.columns\n",
    "    \n",
    "    return lag    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/test.parquet\",exist_ok=True)\n",
    "os.makedirs(\"/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/lags.parquet\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = valid_df.select(test_sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_iterations = len(valid_df[\"date_id\"].unique())\n",
    "total_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 122/122 [00:09<00:00, 12.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for num_days, df_per_day in tqdm(valid_df.group_by(\"date_id\",maintain_order=True),total=total_iterations,desc=\"Processing\"):\n",
    "    \n",
    "       \n",
    "    day = num_days[0] - valid_from # date_id must start from 0.\n",
    "    \n",
    "    os.makedirs(f\"/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/test.parquet/date_id={day}\",exist_ok=True)\n",
    "    os.makedirs(f\"/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/lags.parquet/date_id={day}\",exist_ok=True)\n",
    "    \n",
    "    lag = makelag(num_days[0] - 1)\n",
    "    \n",
    "    df_per_day.write_parquet(f\"/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/test.parquet/date_id={day}/part-0.parquet\")\n",
    "    lag.write_parquet(f\"/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/lags.parquet/date_id={day}/part-0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [s for s in valid_df.columns if \"feature\" in s]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "GatewayRuntimeError",
     "evalue": "(<GatewayRuntimeErrorType.SERVER_RAISED_EXCEPTION: 3>, \"'NoneType' object has no attribute 'filter'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:16\u001b[0m\n",
      "File \u001b[0;32m~/main/kaggle_evaluation/core/templates.py:141\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mstop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/main/kaggle_evaluation/core/templates.py:139\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gateway_for_test(data_paths)\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/main/kaggle_evaluation/core/templates.py:98\u001b[0m, in \u001b[0;36mGateway.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_result(error)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# For local testing\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/main/kaggle_evaluation/core/templates.py:76\u001b[0m, in \u001b[0;36mGateway.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack_data_paths()\n\u001b[0;32m---> 76\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_submission(predictions)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m kaggle_evaluation\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mbase_gateway\u001b[38;5;241m.\u001b[39mGatewayRuntimeError \u001b[38;5;28;01mas\u001b[39;00m gre:\n",
      "File \u001b[0;32m~/main/kaggle_evaluation/core/templates.py:53\u001b[0m, in \u001b[0;36mGateway.get_all_predictions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_batch, validation_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_data_batches():\n\u001b[0;32m---> 53\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_prediction_batch(predictions, validation_batch)\n\u001b[1;32m     55\u001b[0m     all_predictions\u001b[38;5;241m.\u001b[39mappend(predictions)\n",
      "File \u001b[0;32m~/main/kaggle_evaluation/core/templates.py:66\u001b[0m, in \u001b[0;36mGateway.predict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_server_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main/kaggle_evaluation/core/base_gateway.py:191\u001b[0m, in \u001b[0;36mBaseGateway.handle_server_error\u001b[0;34m(self, exception, endpoint)\u001b[0m\n\u001b[1;32m    189\u001b[0m     message_match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException calling application: (.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, exception_str, re\u001b[38;5;241m.\u001b[39mIGNORECASE)\n\u001b[1;32m    190\u001b[0m     message \u001b[38;5;241m=\u001b[39m message_match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m message_match \u001b[38;5;28;01melse\u001b[39;00m exception_str\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatewayRuntimeError(GatewayRuntimeErrorType\u001b[38;5;241m.\u001b[39mSERVER_RAISED_EXCEPTION, message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exception, grpc\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39m_InactiveRpcError):\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatewayRuntimeError(GatewayRuntimeErrorType\u001b[38;5;241m.\u001b[39mSERVER_CONNECTION_FAILED, exception_str) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m: (<GatewayRuntimeErrorType.SERVER_RAISED_EXCEPTION: 3>, \"'NoneType' object has no attribute 'filter'\")"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EVAL = True \n",
    "if EVAL:\n",
    "    test_dir = '/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/test.parquet'\n",
    "    lags_dir = '/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/lags.parquet'\n",
    "else:\n",
    "    test_dir = '/kaggle/input/jane-street-realtime-marketdata-forecasting/test.parquet'\n",
    "    lags_dir = '/kaggle/input/jane-street-realtime-marketdata-forecasting/lags.parquet'\n",
    "\n",
    "import kaggle_evaluation.jane_street_inference_server\n",
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "import os\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            test_dir,\n",
    "            lags_dir\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
